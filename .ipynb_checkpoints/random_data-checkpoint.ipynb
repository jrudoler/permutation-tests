{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from scipy.stats import multivariate_normal, invwishart\n",
    "def random_data_gen(n_samples=1000, n_feats=10, maha=1.0, psi_diag=1.0, psi_offdiag=0., ddof=150, class_ratio=0.5, seed=None):\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "    ## initialize multivariate normal dist with normally distributed means and covariance\n",
    "    ## drawn from an inverse wishart distribution (conjugate prior for MVN)\n",
    "    norm_means_a = np.random.randn(n_feats)\n",
    "    norm_means_b = np.zeros_like(norm_means_a)\n",
    "    psi = psi_diag * np.eye(n_feats) + psi_offdiag * ~np.eye(n_feats).astype(bool)\n",
    "    nu = n_feats + ddof\n",
    "    wishart_cov = invwishart(nu, psi).rvs()\n",
    "    ## specify the mahalanobis distance between the two distributions\n",
    "    dist = mahalanobis(norm_means_a, norm_means_b, wishart_cov)\n",
    "    norm_means_a = norm_means_a * (maha / dist)\n",
    "    assert np.isclose(mahalanobis(norm_means_a, norm_means_b, wishart_cov), maha)\n",
    "    ## multivariate normal distributions with different means and equal variances\n",
    "    mvn_a = multivariate_normal(mean=norm_means_a, cov=wishart_cov)\n",
    "    mvn_b = multivariate_normal(mean=norm_means_b, cov=wishart_cov)\n",
    "    ## not used, but compute correlations\n",
    "    corr = (D:=np.diag(1/np.sqrt(np.diag(wishart_cov)))) @ wishart_cov @ D\n",
    "    ## generate data samples from a multivariate normal\n",
    "    data = np.vstack([mvn_a.rvs(int(n_samples*class_ratio)), mvn_b.rvs(n_samples - int(n_samples*class_ratio))])\n",
    "    labels = np.arange(len(data))<int(n_samples*class_ratio)\n",
    "    return data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import __version__ as v\n",
    "v\n",
    "from scipy import __version__ as v\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-9.15910475e+00, -4.89070990e-02,  2.98483777e+00, ...,\n",
       "          6.33191789e-01,  1.22825385e+00,  7.74653242e-01],\n",
       "        [-9.28514918e+00, -1.74422581e-01,  3.13601087e+00, ...,\n",
       "          7.96529923e-01,  1.05613031e+00,  8.37606569e-01],\n",
       "        [-9.30889080e+00, -1.38971077e-01,  3.21211546e+00, ...,\n",
       "          6.46224059e-01,  9.60843439e-01,  7.78035999e-01],\n",
       "        ...,\n",
       "        [ 3.03177664e-02, -1.39181033e-01,  3.98278450e-02, ...,\n",
       "          1.25858704e-01, -1.80826564e-01, -3.23349127e-03],\n",
       "        [ 7.21363601e-02,  1.13799991e-01, -4.87543905e-02, ...,\n",
       "         -1.19678948e-01,  8.00650982e-02,  3.45938422e-02],\n",
       "        [-2.26635283e-02,  7.59515415e-02, -1.79267798e-01, ...,\n",
       "          2.19843202e-02,  1.34797645e-02,  2.35456576e-02]]),\n",
       " array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False,\n",
       "        False]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data, labels = random_data_gen(n_samples=1000, n_feats=10, maha=1., psi_diag=1.)\n",
    "data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"random_data_X.npy\", data)\n",
    "np.save(\"random_data_y\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_invwish(psi, dof):\n",
    "    n_feats = len(psi)\n",
    "    return psi / (dof-n_feats-1)\n",
    "\n",
    "def Var_invwish(psi, dof):\n",
    "    p = len(psi)\n",
    "    Var = np.empty((p, p))\n",
    "    for i in range(p):\n",
    "        for j in range(p):\n",
    "            Var[i][j] = (dof-p+1) * psi[i][j]**2 + (dof-p-1) * psi[i][i]*psi[j][j] \n",
    "    Var /= (dof-p)*(dof-p-1)**2*(dof-p-3)\n",
    "    return Var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Cov:\n",
      "[[0.02020202 0.         0.         0.         0.        ]\n",
      " [0.         0.02020202 0.         0.         0.        ]\n",
      " [0.         0.         0.02020202 0.         0.        ]\n",
      " [0.         0.         0.         0.02020202 0.        ]\n",
      " [0.         0.         0.         0.         0.02020202]]\n",
      "Expected Corr:\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n",
      "Variance of Cov:\n",
      "[[8.41487877e-06 4.16536499e-06 4.16536499e-06 4.16536499e-06\n",
      "  4.16536499e-06]\n",
      " [4.16536499e-06 8.41487877e-06 4.16536499e-06 4.16536499e-06\n",
      "  4.16536499e-06]\n",
      " [4.16536499e-06 4.16536499e-06 8.41487877e-06 4.16536499e-06\n",
      "  4.16536499e-06]\n",
      " [4.16536499e-06 4.16536499e-06 4.16536499e-06 8.41487877e-06\n",
      "  4.16536499e-06]\n",
      " [4.16536499e-06 4.16536499e-06 4.16536499e-06 4.16536499e-06\n",
      "  8.41487877e-06]]\n"
     ]
    }
   ],
   "source": [
    "def covariance_invwishart(diag=1., offdiag=0., ddof=4, p=5):\n",
    "    psi = diag*np.eye(5) + offdiag * np.ones((p, p))\n",
    "    expected = E_invwish(psi, p+ddof)\n",
    "    variance = Var_invwish(psi, p+ddof)\n",
    "    return expected, variance \n",
    "\n",
    "expected, variance = covariance_invwishart(2, 0, ddof=100)\n",
    "print(f\"Expected Cov:\\n{expected}\")\n",
    "corr = (D:=np.diag(1/np.sqrt(np.diag(expected)))) @ expected @ D\n",
    "print(f\"Expected Corr:\\n{corr}\")\n",
    "print(f\"Variance of Cov:\\n{variance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'psi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_104269/2320953709.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0miw_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minvwishart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miw_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'psi' is not defined"
     ]
    }
   ],
   "source": [
    "iw_dist = invwishart(df=9, scale=psi)\n",
    "iw_dist.rvs(100000).var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = random_data_gen(n_samples=1000, n_feats=10, maha=1., psi_diag=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_covar= np.stack([np.cov(random_data_gen(n_samples=200, n_feats=5, maha=1., psi_diag=1, ddof=150)[0][:100].T) for i in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_corr = np.stack([(D:=np.diag(1/np.sqrt(np.diag(wishart_cov)))) @ wishart_cov @ D for wishart_cov in data_covar])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.        , -0.24966474, -0.26022604, -0.239892  ,\n",
       "         -0.24157122],\n",
       "        [-0.24966474,  1.        , -0.24334487, -0.25067608,\n",
       "         -0.24362033],\n",
       "        [-0.26022604, -0.24334487,  1.        , -0.25619293,\n",
       "         -0.2404409 ],\n",
       "        [-0.239892  , -0.25067608, -0.25619293,  1.        ,\n",
       "         -0.2653355 ],\n",
       "        [-0.24157122, -0.24362033, -0.2404409 , -0.2653355 ,\n",
       "          1.        ]],\n",
       "\n",
       "       [[ 1.        ,  0.24923633,  0.24398142,  0.25127786,\n",
       "          0.24859063],\n",
       "        [ 0.24923633,  1.        ,  0.24425387,  0.23711631,\n",
       "          0.23920541],\n",
       "        [ 0.24398142,  0.24425387,  1.        ,  0.24440722,\n",
       "          0.26522726],\n",
       "        [ 0.25127786,  0.23711631,  0.24440722,  1.        ,\n",
       "          0.24144272],\n",
       "        [ 0.24859063,  0.23920541,  0.26522726,  0.24144272,\n",
       "          1.        ]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.quantile(data_corr, q=[.025, .975], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01,  0.  ,  0.  ,  0.  , -0.  ],\n",
       "       [ 0.  ,  0.01, -0.  ,  0.  , -0.  ],\n",
       "       [ 0.  , -0.  ,  0.01, -0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  , -0.  ,  0.01, -0.  ],\n",
       "       [-0.  , -0.  ,  0.  , -0.  ,  0.01]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data_covar, axis=0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BROKEN: Kronecker product version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def comm_mat(m, n):\n",
    "    # determine permutation applied by K\n",
    "    w = np.arange(m * n).reshape((m, n), order=\"F\").T.ravel(order=\"F\")\n",
    "    # apply this permutation to the rows (i.e. to each column) of identity matrix and return result\n",
    "    return np.eye(m * n)[w, :]\n",
    "\n",
    "def vec(X):\n",
    "    return np.ravel(X, order='F')\n",
    "\n",
    "def kron_Var_invwish(psi, dof):\n",
    "    p = len(psi)\n",
    "    c2 = ((dof - p)*(dof - p - 1)*(dof - p - 3))**(-1)\n",
    "    c1 = (dof-p-2)*c2\n",
    "    c3 = (dof-p-1)**(-2)\n",
    "    K_pp = comm_mat(p, p)\n",
    "    return c1 * np.kron(psi, psi) + c2*vec(psi) @ vec(psi).T + c2 * K_pp @ np.kron(psi, psi) \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a3043ce43b8894bffef93d1839881ad472cb7607c1a3c9f1cfc63c042591dd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
