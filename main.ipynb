{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ac5d68-4055-4066-95c0-a7a5e0a7ca43",
   "metadata": {},
   "source": [
    "# Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "099cd60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home1/jrudoler/anaconda3/envs/py38/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (permutation_test_score, learning_curve, LeaveOneGroupOut,\n",
    "                                     KFold, cross_val_score, cross_val_predict, cross_validate,\n",
    "                                     train_test_split)\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.base import clone\n",
    "from sklearn import datasets\n",
    "from joblib.parallel import Parallel, delayed\n",
    "import pickle\n",
    "from permutation_helpers import random_data_gen, post_hoc_permutation\n",
    "from simulate import simulate\n",
    "from dask.distributed import progress, Client, wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f0030",
   "metadata": {},
   "source": [
    "## Set up client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3dbe440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for jrudoler is 51360\n",
      "{'dashboard_address': ':51360'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN jrudoler@rhino2.psych.upenn.edu -L 8000:192.168.86.120:51360` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n",
      "You've chosen to scale your cluster manually. This means workers will continue to run until you manually shut them down. Remember to run `client.shutdown` after you're done computing and no longer need to reserve resources.\n"
     ]
    }
   ],
   "source": [
    "import cmldask.CMLDask as da\n",
    "rhino_client = da.new_dask_client_slurm(\n",
    "    job_name=\"simulations\",\n",
    "    memory_per_job=\"2GB\",\n",
    "    max_n_jobs=400, threads_per_job=1, \n",
    "    adapt=False,\n",
    "    local_directory=\"/home1/jrudoler/dask-worker-space\",\n",
    "    log_directory=\"/home1/jrudoler/logs/\",\n",
    "#     resource_spec=\"h_vmem=2.5G,s_vmem=2.5G\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d26220b5-6c80-4df0-ba5e-e43a3cd32b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rhino_client.cluster.scale(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67942258",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9af3f",
   "metadata": {},
   "source": [
    "# Post-hoc simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad8803",
   "metadata": {},
   "source": [
    "#### Post-hoc simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f932880",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shared parameters\n",
    "class_params = {\n",
    "        \"C\":np.logspace(np.log10(1e-4), np.log10(1e5), 8),\n",
    "        \"class_weight\":\"balanced\"\n",
    "    }\n",
    "permutation_params = {\n",
    "        \"n_permutations\": 5000\n",
    "    }\n",
    "sim_params = {\"n_sim\": 500}\n",
    "data_gen_params = {\n",
    "    \"maha\":np.linspace(0., 1.5, 5)[4],\n",
    "    \"psi_diag\": 1.0,\n",
    "    \"psi_offdiag\": 0.,\n",
    "    \"ddof\": 150\n",
    "}\n",
    "samplesize_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"maha\":0.,\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "        \n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "nfeats_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"maha\":0.,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "ratio_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        \"maha\":0.,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "testsize_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50323c21",
   "metadata": {},
   "source": [
    "#### Simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eccfaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n"
     ]
    }
   ],
   "source": [
    "@simulate(**samplesize_params_post[\"sim\"])\n",
    "def simulate_samplesize_post(param=None, seed=None, settings=samplesize_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**testsize_params_post[\"sim\"])\n",
    "def simulate_testsize_post(param=None, seed=None, settings=testsize_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**nfeats_params_post[\"sim\"])\n",
    "def simulate_nfeats_post(param=None, seed=None, settings=nfeats_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**ratio_params_post[\"sim\"])\n",
    "def simulate_ratio_post(param=None, seed=None, settings=ratio_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941b9ea",
   "metadata": {},
   "source": [
    "#### Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27286a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
    "samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
    "nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
    "ratio_futures_post, ratio_gather = simulate_ratio_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603cac4",
   "metadata": {},
   "source": [
    "#### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2e6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"sim_results/maha_{data_gen_params['maha']:.1f}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc05025",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(testsize_futures_post)\n",
    "testsize_result = testsize_gather(testsize_futures_post) \n",
    "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = testsize_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_post.pkl\")\n",
    "rhino_client.cancel(testsize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbffffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(samplesize_futures_post)\n",
    "samplesize_result = samplesize_gather(samplesize_futures_post) \n",
    "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = samplesize_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_post.pkl\")\n",
    "rhino_client.cancel(samplesize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f3154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(nfeats_futures_post)\n",
    "nfeats_result = nfeats_gather(nfeats_futures_post)\n",
    "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = nfeats_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_post.pkl\")\n",
    "rhino_client.cancel(nfeats_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d7efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(ratio_futures_post)\n",
    "ratio_result = ratio_gather(ratio_futures_post)\n",
    "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = ratio_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_post.pkl\")\n",
    "rhino_client.cancel(ratio_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a7b42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(samplesize_futures_post + ratio_futures_post + nfeats_futures_post + testsize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c1692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8ce51c6-b8de-4647-9db9-a496a3d93a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exception</th>\n",
       "      <th>traceback_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9abcecd00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9b89c7440&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9de046f80&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9dfab0300&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9abc862c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bbbfdec0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9aab40f80&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df2aeb40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df71c4c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9cf67c380&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df1df1c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df880740&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9cca429c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df360680&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9ded7ac40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9dfa245c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bae08340&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>715</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df09bdc0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9cd8ed780&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df722780&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bb894e80&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bbd96d40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df6e47c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df717b00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1225</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df9928c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df8b0280&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df943b80&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df88ef00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df2b3280&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df3efec0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1305</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9de9de0c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bafa8c00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9dfa271c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df55fb40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9dfaf0f40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1570</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df516b00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9bb975a40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9ab588400&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9ab7f2600&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1855</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df7dfb40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df829d00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df54f2c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9df3759c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2105</th>\n",
       "      <td>ValueError('Only one class present in y_true. ...</td>\n",
       "      <td>&lt;traceback object at 0x2ab9dfae9780&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               exception  \\\n",
       "param                                                      \n",
       "35     ValueError('Only one class present in y_true. ...   \n",
       "40     ValueError('Only one class present in y_true. ...   \n",
       "105    ValueError('Only one class present in y_true. ...   \n",
       "120    ValueError('Only one class present in y_true. ...   \n",
       "255    ValueError('Only one class present in y_true. ...   \n",
       "256    ValueError('Only one class present in y_true. ...   \n",
       "260    ValueError('Only one class present in y_true. ...   \n",
       "295    ValueError('Only one class present in y_true. ...   \n",
       "330    ValueError('Only one class present in y_true. ...   \n",
       "335    ValueError('Only one class present in y_true. ...   \n",
       "385    ValueError('Only one class present in y_true. ...   \n",
       "435    ValueError('Only one class present in y_true. ...   \n",
       "475    ValueError('Only one class present in y_true. ...   \n",
       "510    ValueError('Only one class present in y_true. ...   \n",
       "625    ValueError('Only one class present in y_true. ...   \n",
       "665    ValueError('Only one class present in y_true. ...   \n",
       "700    ValueError('Only one class present in y_true. ...   \n",
       "715    ValueError('Only one class present in y_true. ...   \n",
       "730    ValueError('Only one class present in y_true. ...   \n",
       "810    ValueError('Only one class present in y_true. ...   \n",
       "870    ValueError('Only one class present in y_true. ...   \n",
       "965    ValueError('Only one class present in y_true. ...   \n",
       "1090   ValueError('Only one class present in y_true. ...   \n",
       "1135   ValueError('Only one class present in y_true. ...   \n",
       "1225   ValueError('Only one class present in y_true. ...   \n",
       "1235   ValueError('Only one class present in y_true. ...   \n",
       "1255   ValueError('Only one class present in y_true. ...   \n",
       "1265   ValueError('Only one class present in y_true. ...   \n",
       "1285   ValueError('Only one class present in y_true. ...   \n",
       "1290   ValueError('Only one class present in y_true. ...   \n",
       "1305   ValueError('Only one class present in y_true. ...   \n",
       "1355   ValueError('Only one class present in y_true. ...   \n",
       "1370   ValueError('Only one class present in y_true. ...   \n",
       "1475   ValueError('Only one class present in y_true. ...   \n",
       "1515   ValueError('Only one class present in y_true. ...   \n",
       "1570   ValueError('Only one class present in y_true. ...   \n",
       "1725   ValueError('Only one class present in y_true. ...   \n",
       "1805   ValueError('Only one class present in y_true. ...   \n",
       "1830   ValueError('Only one class present in y_true. ...   \n",
       "1855   ValueError('Only one class present in y_true. ...   \n",
       "1875   ValueError('Only one class present in y_true. ...   \n",
       "1915   ValueError('Only one class present in y_true. ...   \n",
       "2025   ValueError('Only one class present in y_true. ...   \n",
       "2105   ValueError('Only one class present in y_true. ...   \n",
       "\n",
       "                              traceback_obj  \n",
       "param                                        \n",
       "35     <traceback object at 0x2ab9abcecd00>  \n",
       "40     <traceback object at 0x2ab9b89c7440>  \n",
       "105    <traceback object at 0x2ab9de046f80>  \n",
       "120    <traceback object at 0x2ab9dfab0300>  \n",
       "255    <traceback object at 0x2ab9abc862c0>  \n",
       "256    <traceback object at 0x2ab9bbbfdec0>  \n",
       "260    <traceback object at 0x2ab9aab40f80>  \n",
       "295    <traceback object at 0x2ab9df2aeb40>  \n",
       "330    <traceback object at 0x2ab9df71c4c0>  \n",
       "335    <traceback object at 0x2ab9cf67c380>  \n",
       "385    <traceback object at 0x2ab9df1df1c0>  \n",
       "435    <traceback object at 0x2ab9df880740>  \n",
       "475    <traceback object at 0x2ab9cca429c0>  \n",
       "510    <traceback object at 0x2ab9df360680>  \n",
       "625    <traceback object at 0x2ab9ded7ac40>  \n",
       "665    <traceback object at 0x2ab9dfa245c0>  \n",
       "700    <traceback object at 0x2ab9bae08340>  \n",
       "715    <traceback object at 0x2ab9df09bdc0>  \n",
       "730    <traceback object at 0x2ab9cd8ed780>  \n",
       "810    <traceback object at 0x2ab9df722780>  \n",
       "870    <traceback object at 0x2ab9bb894e80>  \n",
       "965    <traceback object at 0x2ab9bbd96d40>  \n",
       "1090   <traceback object at 0x2ab9df6e47c0>  \n",
       "1135   <traceback object at 0x2ab9df717b00>  \n",
       "1225   <traceback object at 0x2ab9df9928c0>  \n",
       "1235   <traceback object at 0x2ab9df8b0280>  \n",
       "1255   <traceback object at 0x2ab9df943b80>  \n",
       "1265   <traceback object at 0x2ab9df88ef00>  \n",
       "1285   <traceback object at 0x2ab9df2b3280>  \n",
       "1290   <traceback object at 0x2ab9df3efec0>  \n",
       "1305   <traceback object at 0x2ab9de9de0c0>  \n",
       "1355   <traceback object at 0x2ab9bafa8c00>  \n",
       "1370   <traceback object at 0x2ab9dfa271c0>  \n",
       "1475   <traceback object at 0x2ab9df55fb40>  \n",
       "1515   <traceback object at 0x2ab9dfaf0f40>  \n",
       "1570   <traceback object at 0x2ab9df516b00>  \n",
       "1725   <traceback object at 0x2ab9bb975a40>  \n",
       "1805   <traceback object at 0x2ab9ab588400>  \n",
       "1830   <traceback object at 0x2ab9ab7f2600>  \n",
       "1855   <traceback object at 0x2ab9df7dfb40>  \n",
       "1875   <traceback object at 0x2ab9df829d00>  \n",
       "1915   <traceback object at 0x2ab9df54f2c0>  \n",
       "2025   <traceback object at 0x2ab9df3759c0>  \n",
       "2105   <traceback object at 0x2ab9dfae9780>  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.get_exceptions(ratio_futures_pre, np.arange(len(samplesize_futures_post)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab71d2",
   "metadata": {},
   "source": [
    "# Pre-training permutations (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f2519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_score(estimator, X_train, X_test, y_train, y_test, \n",
    "                score_func, shuffle_labels=False):\n",
    "    if shuffle_labels:\n",
    "        indices = np.random.default_rng().permutation(len(y_train))\n",
    "        y_train = y_train[indices]\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:,1]\n",
    "    score = score_func(y_true=y_test, y_score=y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def pre_training_permutation(estimator, X_train, X_test, y_train, y_test,\n",
    "                            n_permutations, score_func, verbose=False, n_jobs=None):\n",
    "    score = _train_score(\n",
    "        clone(estimator), X_train, X_test, y_train, y_test, score_func, shuffle_labels=False\n",
    "    )\n",
    "    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_train_score)(\n",
    "            clone(estimator),\n",
    "            X_train, X_test, y_train, y_test,\n",
    "            score_func,\n",
    "            shuffle_labels=True,\n",
    "        )\n",
    "        for _ in range(n_permutations)\n",
    "    )\n",
    "    permutation_scores = np.array(permutation_scores)\n",
    "    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n",
    "    return score, permutation_scores, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f9fb8",
   "metadata": {},
   "source": [
    "#### Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca895a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shared parameters\n",
    "# class_params = {\n",
    "#     \"C\":1e-3,\n",
    "#     \"class_weight\":\"balanced\"\n",
    "# }\n",
    "# permutation_params = {\n",
    "#     \"n_permutations\": 5000\n",
    "# }\n",
    "# sim_params = {\"n_sim\": 150}\n",
    "# data_gen_params = {\n",
    "#     \"maha\":np.linspace(0., 1.5, 5)[0],\n",
    "#     \"psi_diag\": 1.0,\n",
    "#     \"psi_offdiag\": 0.,\n",
    "#     \"ddof\": 150\n",
    "# }\n",
    "samplesize_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "        \n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "nfeats_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "ratio_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "testsize_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8088e",
   "metadata": {},
   "source": [
    "#### Simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70173f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n"
     ]
    }
   ],
   "source": [
    "@simulate(**samplesize_params_pre[\"sim\"])\n",
    "def simulate_samplesize_pre(param=None, seed=None, settings=samplesize_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**testsize_params_pre[\"sim\"])\n",
    "def simulate_testsize_pre(param=None, seed=None, settings=testsize_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**nfeats_params_pre[\"sim\"])\n",
    "def simulate_nfeats_pre(param=None, seed=None, settings=nfeats_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**ratio_params_pre[\"sim\"])\n",
    "def simulate_ratio_pre(param=None, seed=None, settings=ratio_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a79c1-efce-4a4f-a46b-882d3e200d8f",
   "metadata": {},
   "source": [
    "#### Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e26d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
    "samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
    "nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
    "ratio_futures_pre, ratio_gather = simulate_ratio_pre()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc558269-d70f-4bd0-9822-d9538850297b",
   "metadata": {},
   "source": [
    "#### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65445e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(testsize_futures_pre)\n",
    "testsize_result = testsize_gather(testsize_futures_pre) \n",
    "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = testsize_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_pre.pkl\")\n",
    "rhino_client.cancel(testsize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754db625",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(samplesize_futures_pre)\n",
    "samplesize_result = samplesize_gather(samplesize_futures_pre) \n",
    "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = samplesize_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_pre.pkl\")\n",
    "rhino_client.cancel(samplesize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe27f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(nfeats_futures_pre)\n",
    "nfeats_result = nfeats_gather(nfeats_futures_pre)\n",
    "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = nfeats_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_pre.pkl\")\n",
    "rhino_client.cancel(nfeats_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(ratio_futures_pre)\n",
    "ratio_result = ratio_gather(ratio_futures_pre)\n",
    "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = ratio_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_pre.pkl\")\n",
    "rhino_client.cancel(ratio_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f459839-0113-4b79-8dff-8a9808882216",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(ratio_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5de0fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(ratio_futures_pre+nfeats_futures_pre+samplesize_futures_pre+testsize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e87e2457-c95f-4af5-8c11-9b52b1ff06ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exception</th>\n",
       "      <th>traceback_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b42fe391ec0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4320207f40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b432015bc00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43099f7640&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43250bb100&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4320f934c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b434257e440&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4342099880&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4313809600&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43131e3800&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               exception  \\\n",
       "param                                                      \n",
       "0      NameError(\"name 'pre_training_permutation' is ...   \n",
       "1      NameError(\"name 'pre_training_permutation' is ...   \n",
       "2      NameError(\"name 'pre_training_permutation' is ...   \n",
       "3      NameError(\"name 'pre_training_permutation' is ...   \n",
       "4      NameError(\"name 'pre_training_permutation' is ...   \n",
       "...                                                  ...   \n",
       "2495   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2496   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2497   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2498   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2499   NameError(\"name 'pre_training_permutation' is ...   \n",
       "\n",
       "                              traceback_obj  \n",
       "param                                        \n",
       "0      <traceback object at 0x2b42fe391ec0>  \n",
       "1      <traceback object at 0x2b4320207f40>  \n",
       "2      <traceback object at 0x2b432015bc00>  \n",
       "3      <traceback object at 0x2b43099f7640>  \n",
       "4      <traceback object at 0x2b43250bb100>  \n",
       "...                                     ...  \n",
       "2495   <traceback object at 0x2b4320f934c0>  \n",
       "2496   <traceback object at 0x2b434257e440>  \n",
       "2497   <traceback object at 0x2b4342099880>  \n",
       "2498   <traceback object at 0x2b4313809600>  \n",
       "2499   <traceback object at 0x2b43131e3800>  \n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.get_exceptions(samplesize_futures_pre, range(len(samplesize_futures_pre)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e3da1-4763-4dd5-bf3a-846bd26be597",
   "metadata": {},
   "source": [
    "# Comparing runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c124317-7960-4658-8b8e-d65c15309108",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def runtime(f, *args, **kwargs):\n",
    "    start = time.time()\n",
    "    f(*args, **kwargs)\n",
    "    stop = time.time()\n",
    "    return stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae17d012-36db-417d-b027-95e1e1da0b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.120:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.120:51360/status\n"
     ]
    }
   ],
   "source": [
    "runtime_params = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "@simulate(**runtime_params[\"sim\"])\n",
    "def simulate_runtime_pre(param=None, seed=None, settings=runtime_params):\n",
    "    start = time.time()\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    stop = time.time()\n",
    "    return stop - start\n",
    "\n",
    "@simulate(**runtime_params[\"sim\"])\n",
    "def simulate_runtime_post(param=None, seed=None, settings=runtime_params):\n",
    "    start = time.time()\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    stop = time.time()\n",
    "    return stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ef8706-3676-4d6e-a650-34eb85eb7f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "runtime_futures_pre, runtime_gather = simulate_runtime_pre()\n",
    "runtime_futures_post, runtime_gather = simulate_runtime_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48809492-c2ea-4b78-829f-0b93d76e1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wait(runtime_futures_pre)\n",
    "\n",
    "# df_result._metadata = runtime_params\n",
    "# df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_pre.pkl\")\n",
    "rhino_client.cancel(runtime_futures_pre+runtime_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d57fba68-910f-4e9c-80f2-3182889f597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_result_pre = runtime_gather(runtime_futures_pre)\n",
    "runtime_result_post = runtime_gather(runtime_futures_post)\n",
    "df_result_pre = pd.DataFrame(runtime_result_pre).melt(var_name=\"param\")\n",
    "df_result_post = pd.DataFrame(runtime_result_post).melt(var_name=\"param\")\n",
    "df_result_pre['test'] = 'pre'\n",
    "df_result_post['test'] = 'post'\n",
    "df_result = pd.concat([df_result_pre, df_result_post])\n",
    "df_result._metadata = runtime_params\n",
    "df_result.to_pickle(f\"sim_results/simulate_runtime.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5164f6b7",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32a3e3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique port for jrudoler is 51360\n",
      "{'dashboard_address': ':51360'}\n",
      "To view the dashboard, run: \n",
      "`ssh -fN jrudoler@rhino2.psych.upenn.edu -L 8000:192.168.86.106:51360` in your local computer's terminal (NOT rhino) \n",
      "and then navigate to localhost:8000 in your browser\n"
     ]
    }
   ],
   "source": [
    "import cmldask.CMLDask as da\n",
    "rhino_client = da.new_dask_client_slurm(\n",
    "    job_name=\"C_tuning\",\n",
    "    memory_per_job=\"1.5GB\",\n",
    "    max_n_jobs=50,\n",
    "    threads_per_job=1, \n",
    "    adapt=True,\n",
    "    local_directory=\"/home1/jrudoler/\",\n",
    "    log_directory=\"/home1/jrudoler/logs/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cda187d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 200 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n"
     ]
    }
   ],
   "source": [
    "# TODO: Return all AUC scores for all C values, not just the best one. \n",
    "@simulate(parameter_range=np.linspace(0., 1.5, 5), n_sim=200)\n",
    "def test_best_C(param=None, seed=None):\n",
    "    X, y = random_data_gen(n_samples=5000, n_feats=10, maha=param, class_ratio=0.5, seed=seed)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    estimator = LogisticRegressionCV(class_weight='balanced', Cs=np.logspace(np.log10(1e-3), np.log10(1e6), 15))\n",
    "    estimator.fit(X_train, y_train)\n",
    "    pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    return roc_auc_score(y_true=y_test, y_score=pred), estimator.C_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "301a57a1-a349-4bde-9751-20ac71f25a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-04, 1.29154967e-03, 1.66810054e-02, 2.15443469e-01,\n",
       "       2.78255940e+00, 3.59381366e+01, 4.64158883e+02, 5.99484250e+03,\n",
       "       7.74263683e+04, 1.00000000e+06])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(np.log10(1e-4), np.log10(1e6), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302b3a50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "C_futures, C_gather = test_best_C()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d08f4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(C_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65882064",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85f78141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2cb4c690514e27bfe34ed53543e918",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "progress(C_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4b341a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_results = C_gather(C_futures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb90cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(C_results).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"C\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec441a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param</th>\n",
       "      <th>C</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">0.000</th>\n",
       "      <th>0.001000</th>\n",
       "      <td>51.0</td>\n",
       "      <td>0.500189</td>\n",
       "      <td>0.014283</td>\n",
       "      <td>0.472552</td>\n",
       "      <td>0.488991</td>\n",
       "      <td>0.500460</td>\n",
       "      <td>0.508796</td>\n",
       "      <td>0.528035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004394</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.500041</td>\n",
       "      <td>0.019120</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>0.486804</td>\n",
       "      <td>0.498724</td>\n",
       "      <td>0.513394</td>\n",
       "      <td>0.538359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.019307</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.501062</td>\n",
       "      <td>0.018689</td>\n",
       "      <td>0.476384</td>\n",
       "      <td>0.487279</td>\n",
       "      <td>0.494766</td>\n",
       "      <td>0.514531</td>\n",
       "      <td>0.546536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084834</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.502859</td>\n",
       "      <td>0.017194</td>\n",
       "      <td>0.468201</td>\n",
       "      <td>0.491137</td>\n",
       "      <td>0.500589</td>\n",
       "      <td>0.510608</td>\n",
       "      <td>0.540863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372759</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.495200</td>\n",
       "      <td>0.025852</td>\n",
       "      <td>0.453977</td>\n",
       "      <td>0.478291</td>\n",
       "      <td>0.498051</td>\n",
       "      <td>0.505587</td>\n",
       "      <td>0.540648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.637894</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.502319</td>\n",
       "      <td>0.016872</td>\n",
       "      <td>0.476178</td>\n",
       "      <td>0.492074</td>\n",
       "      <td>0.500702</td>\n",
       "      <td>0.518141</td>\n",
       "      <td>0.529839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.196857</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.503450</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>0.480454</td>\n",
       "      <td>0.489900</td>\n",
       "      <td>0.502414</td>\n",
       "      <td>0.515212</td>\n",
       "      <td>0.531061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.622777</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.488825</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.476941</td>\n",
       "      <td>0.481053</td>\n",
       "      <td>0.490806</td>\n",
       "      <td>0.496646</td>\n",
       "      <td>0.498003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.949549</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.483678</td>\n",
       "      <td>0.021437</td>\n",
       "      <td>0.455054</td>\n",
       "      <td>0.468840</td>\n",
       "      <td>0.491178</td>\n",
       "      <td>0.494738</td>\n",
       "      <td>0.508580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610.540230</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.498185</td>\n",
       "      <td>0.010658</td>\n",
       "      <td>0.483410</td>\n",
       "      <td>0.492416</td>\n",
       "      <td>0.496817</td>\n",
       "      <td>0.506549</td>\n",
       "      <td>0.511327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682.695795</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.493460</td>\n",
       "      <td>0.007556</td>\n",
       "      <td>0.481519</td>\n",
       "      <td>0.493170</td>\n",
       "      <td>0.493292</td>\n",
       "      <td>0.497566</td>\n",
       "      <td>0.501755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51794.746792</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.498608</td>\n",
       "      <td>0.498608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227584.592607</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>0.545803</td>\n",
       "      <td>0.545803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">0.375</th>\n",
       "      <th>0.001000</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.594604</td>\n",
       "      <td>0.023669</td>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.573382</td>\n",
       "      <td>0.596108</td>\n",
       "      <td>0.612808</td>\n",
       "      <td>0.632179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004394</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.599043</td>\n",
       "      <td>0.017942</td>\n",
       "      <td>0.571149</td>\n",
       "      <td>0.585270</td>\n",
       "      <td>0.599326</td>\n",
       "      <td>0.606894</td>\n",
       "      <td>0.639479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.019307</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.602057</td>\n",
       "      <td>0.018132</td>\n",
       "      <td>0.571644</td>\n",
       "      <td>0.593126</td>\n",
       "      <td>0.603285</td>\n",
       "      <td>0.612182</td>\n",
       "      <td>0.641670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084834</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.600038</td>\n",
       "      <td>0.017353</td>\n",
       "      <td>0.578925</td>\n",
       "      <td>0.585954</td>\n",
       "      <td>0.596885</td>\n",
       "      <td>0.613764</td>\n",
       "      <td>0.641160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372759</th>\n",
       "      <td>33.0</td>\n",
       "      <td>0.602881</td>\n",
       "      <td>0.017407</td>\n",
       "      <td>0.578062</td>\n",
       "      <td>0.590328</td>\n",
       "      <td>0.597654</td>\n",
       "      <td>0.612045</td>\n",
       "      <td>0.646583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.637894</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.603468</td>\n",
       "      <td>0.020501</td>\n",
       "      <td>0.562991</td>\n",
       "      <td>0.587174</td>\n",
       "      <td>0.604611</td>\n",
       "      <td>0.620848</td>\n",
       "      <td>0.643448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.196857</th>\n",
       "      <td>22.0</td>\n",
       "      <td>0.601586</td>\n",
       "      <td>0.015666</td>\n",
       "      <td>0.580664</td>\n",
       "      <td>0.590070</td>\n",
       "      <td>0.597523</td>\n",
       "      <td>0.608600</td>\n",
       "      <td>0.646863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.622777</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.599176</td>\n",
       "      <td>0.016564</td>\n",
       "      <td>0.555109</td>\n",
       "      <td>0.591145</td>\n",
       "      <td>0.600518</td>\n",
       "      <td>0.609944</td>\n",
       "      <td>0.623456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.949549</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.603724</td>\n",
       "      <td>0.018639</td>\n",
       "      <td>0.564210</td>\n",
       "      <td>0.592799</td>\n",
       "      <td>0.602840</td>\n",
       "      <td>0.611907</td>\n",
       "      <td>0.632687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610.540230</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.611349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611349</td>\n",
       "      <td>0.611349</td>\n",
       "      <td>0.611349</td>\n",
       "      <td>0.611349</td>\n",
       "      <td>0.611349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682.695795</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.592897</td>\n",
       "      <td>0.027000</td>\n",
       "      <td>0.570596</td>\n",
       "      <td>0.574472</td>\n",
       "      <td>0.585396</td>\n",
       "      <td>0.603821</td>\n",
       "      <td>0.630200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787.686348</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.604891</td>\n",
       "      <td>0.604891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51794.746792</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>0.609516</td>\n",
       "      <td>0.609516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">0.750</th>\n",
       "      <th>0.001000</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.020048</td>\n",
       "      <td>0.669878</td>\n",
       "      <td>0.679812</td>\n",
       "      <td>0.708005</td>\n",
       "      <td>0.716724</td>\n",
       "      <td>0.718199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004394</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.694352</td>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.681569</td>\n",
       "      <td>0.686802</td>\n",
       "      <td>0.693118</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.707072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.019307</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.697783</td>\n",
       "      <td>0.012809</td>\n",
       "      <td>0.668708</td>\n",
       "      <td>0.693373</td>\n",
       "      <td>0.697207</td>\n",
       "      <td>0.703383</td>\n",
       "      <td>0.719648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084834</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.700481</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.670866</td>\n",
       "      <td>0.692712</td>\n",
       "      <td>0.703244</td>\n",
       "      <td>0.708763</td>\n",
       "      <td>0.724190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372759</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.704001</td>\n",
       "      <td>0.016532</td>\n",
       "      <td>0.672575</td>\n",
       "      <td>0.690502</td>\n",
       "      <td>0.700693</td>\n",
       "      <td>0.716803</td>\n",
       "      <td>0.736704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.637894</th>\n",
       "      <td>39.0</td>\n",
       "      <td>0.700479</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>0.659323</td>\n",
       "      <td>0.691699</td>\n",
       "      <td>0.699717</td>\n",
       "      <td>0.712613</td>\n",
       "      <td>0.736435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.196857</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.699809</td>\n",
       "      <td>0.020306</td>\n",
       "      <td>0.661055</td>\n",
       "      <td>0.687653</td>\n",
       "      <td>0.699470</td>\n",
       "      <td>0.714588</td>\n",
       "      <td>0.738425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.622777</th>\n",
       "      <td>27.0</td>\n",
       "      <td>0.707750</td>\n",
       "      <td>0.016892</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.696054</td>\n",
       "      <td>0.707129</td>\n",
       "      <td>0.718402</td>\n",
       "      <td>0.738597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.949549</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.694726</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.651374</td>\n",
       "      <td>0.686788</td>\n",
       "      <td>0.693359</td>\n",
       "      <td>0.704150</td>\n",
       "      <td>0.733584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610.540230</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.700462</td>\n",
       "      <td>0.011293</td>\n",
       "      <td>0.687362</td>\n",
       "      <td>0.694411</td>\n",
       "      <td>0.700163</td>\n",
       "      <td>0.706213</td>\n",
       "      <td>0.714161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682.695795</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.700894</td>\n",
       "      <td>0.012433</td>\n",
       "      <td>0.678676</td>\n",
       "      <td>0.705791</td>\n",
       "      <td>0.706203</td>\n",
       "      <td>0.706439</td>\n",
       "      <td>0.707361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">1.125</th>\n",
       "      <th>0.001000</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.764602</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.757236</td>\n",
       "      <td>0.758531</td>\n",
       "      <td>0.759809</td>\n",
       "      <td>0.763282</td>\n",
       "      <td>0.791540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004394</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.777013</td>\n",
       "      <td>0.013026</td>\n",
       "      <td>0.765176</td>\n",
       "      <td>0.767659</td>\n",
       "      <td>0.775545</td>\n",
       "      <td>0.778927</td>\n",
       "      <td>0.800729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.019307</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.792030</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.788618</td>\n",
       "      <td>0.789388</td>\n",
       "      <td>0.790402</td>\n",
       "      <td>0.793045</td>\n",
       "      <td>0.798699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084834</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.784655</td>\n",
       "      <td>0.018792</td>\n",
       "      <td>0.740827</td>\n",
       "      <td>0.781392</td>\n",
       "      <td>0.788342</td>\n",
       "      <td>0.796284</td>\n",
       "      <td>0.808542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372759</th>\n",
       "      <td>38.0</td>\n",
       "      <td>0.786210</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.754517</td>\n",
       "      <td>0.777411</td>\n",
       "      <td>0.784494</td>\n",
       "      <td>0.795426</td>\n",
       "      <td>0.820522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.637894</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.785741</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.754877</td>\n",
       "      <td>0.776449</td>\n",
       "      <td>0.785682</td>\n",
       "      <td>0.796912</td>\n",
       "      <td>0.816484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.196857</th>\n",
       "      <td>28.0</td>\n",
       "      <td>0.781825</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>0.752816</td>\n",
       "      <td>0.774415</td>\n",
       "      <td>0.779885</td>\n",
       "      <td>0.792605</td>\n",
       "      <td>0.809134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.622777</th>\n",
       "      <td>26.0</td>\n",
       "      <td>0.790781</td>\n",
       "      <td>0.010226</td>\n",
       "      <td>0.770363</td>\n",
       "      <td>0.785133</td>\n",
       "      <td>0.788923</td>\n",
       "      <td>0.797836</td>\n",
       "      <td>0.813304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.949549</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.787554</td>\n",
       "      <td>0.018293</td>\n",
       "      <td>0.753575</td>\n",
       "      <td>0.775278</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.792839</td>\n",
       "      <td>0.818734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610.540230</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.017300</td>\n",
       "      <td>0.762592</td>\n",
       "      <td>0.775948</td>\n",
       "      <td>0.780088</td>\n",
       "      <td>0.787182</td>\n",
       "      <td>0.817098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787.686348</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.790579</td>\n",
       "      <td>0.790579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51794.746792</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>0.774319</td>\n",
       "      <td>0.774319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227584.592607</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.775252</td>\n",
       "      <td>0.775252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">1.500</th>\n",
       "      <th>0.001000</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.855553</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.849032</td>\n",
       "      <td>0.850285</td>\n",
       "      <td>0.852637</td>\n",
       "      <td>0.857906</td>\n",
       "      <td>0.867908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.004394</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.836696</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.833657</td>\n",
       "      <td>0.835177</td>\n",
       "      <td>0.836696</td>\n",
       "      <td>0.838216</td>\n",
       "      <td>0.839735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.019307</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>0.832359</td>\n",
       "      <td>0.832359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.084834</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.854349</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.832575</td>\n",
       "      <td>0.850241</td>\n",
       "      <td>0.854107</td>\n",
       "      <td>0.857014</td>\n",
       "      <td>0.872553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.372759</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.852706</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>0.825475</td>\n",
       "      <td>0.846105</td>\n",
       "      <td>0.853751</td>\n",
       "      <td>0.859748</td>\n",
       "      <td>0.874403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.637894</th>\n",
       "      <td>43.0</td>\n",
       "      <td>0.855124</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.832043</td>\n",
       "      <td>0.846238</td>\n",
       "      <td>0.856479</td>\n",
       "      <td>0.864740</td>\n",
       "      <td>0.875084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.196857</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.857269</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.830886</td>\n",
       "      <td>0.847886</td>\n",
       "      <td>0.858415</td>\n",
       "      <td>0.866666</td>\n",
       "      <td>0.883515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31.622777</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.856382</td>\n",
       "      <td>0.011398</td>\n",
       "      <td>0.841490</td>\n",
       "      <td>0.847644</td>\n",
       "      <td>0.855714</td>\n",
       "      <td>0.864025</td>\n",
       "      <td>0.877580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138.949549</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.858096</td>\n",
       "      <td>0.009986</td>\n",
       "      <td>0.841111</td>\n",
       "      <td>0.854616</td>\n",
       "      <td>0.858083</td>\n",
       "      <td>0.865646</td>\n",
       "      <td>0.872432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610.540230</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.853926</td>\n",
       "      <td>0.010041</td>\n",
       "      <td>0.835048</td>\n",
       "      <td>0.846991</td>\n",
       "      <td>0.855413</td>\n",
       "      <td>0.862594</td>\n",
       "      <td>0.865252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2682.695795</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.851306</td>\n",
       "      <td>0.001925</td>\n",
       "      <td>0.849945</td>\n",
       "      <td>0.850626</td>\n",
       "      <td>0.851306</td>\n",
       "      <td>0.851987</td>\n",
       "      <td>0.852667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11787.686348</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.838245</td>\n",
       "      <td>0.838245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    score                                                    \\\n",
       "                    count      mean       std       min       25%       50%   \n",
       "param C                                                                       \n",
       "0.000 0.001000       51.0  0.500189  0.014283  0.472552  0.488991  0.500460   \n",
       "      0.004394       40.0  0.500041  0.019120  0.462883  0.486804  0.498724   \n",
       "      0.019307       27.0  0.501062  0.018689  0.476384  0.487279  0.494766   \n",
       "      0.084834       25.0  0.502859  0.017194  0.468201  0.491137  0.500589   \n",
       "      0.372759        8.0  0.495200  0.025852  0.453977  0.478291  0.498051   \n",
       "      1.637894       18.0  0.502319  0.016872  0.476178  0.492074  0.500702   \n",
       "      7.196857        7.0  0.503450  0.019665  0.480454  0.489900  0.502414   \n",
       "      31.622777       6.0  0.488825  0.009346  0.476941  0.481053  0.490806   \n",
       "      138.949549      5.0  0.483678  0.021437  0.455054  0.468840  0.491178   \n",
       "      610.540230      6.0  0.498185  0.010658  0.483410  0.492416  0.496817   \n",
       "      2682.695795     5.0  0.493460  0.007556  0.481519  0.493170  0.493292   \n",
       "      51794.746792    1.0  0.498608       NaN  0.498608  0.498608  0.498608   \n",
       "      227584.592607   1.0  0.545803       NaN  0.545803  0.545803  0.545803   \n",
       "0.375 0.001000       15.0  0.594604  0.023669  0.551183  0.573382  0.596108   \n",
       "      0.004394       15.0  0.599043  0.017942  0.571149  0.585270  0.599326   \n",
       "      0.019307       20.0  0.602057  0.018132  0.571644  0.593126  0.603285   \n",
       "      0.084834       18.0  0.600038  0.017353  0.578925  0.585954  0.596885   \n",
       "      0.372759       33.0  0.602881  0.017407  0.578062  0.590328  0.597654   \n",
       "      1.637894       32.0  0.603468  0.020501  0.562991  0.587174  0.604611   \n",
       "      7.196857       22.0  0.601586  0.015666  0.580664  0.590070  0.597523   \n",
       "      31.622777      20.0  0.599176  0.016564  0.555109  0.591145  0.600518   \n",
       "      138.949549     18.0  0.603724  0.018639  0.564210  0.592799  0.602840   \n",
       "      610.540230      1.0  0.611349       NaN  0.611349  0.611349  0.611349   \n",
       "      2682.695795     4.0  0.592897  0.027000  0.570596  0.574472  0.585396   \n",
       "      11787.686348    1.0  0.604891       NaN  0.604891  0.604891  0.604891   \n",
       "      51794.746792    1.0  0.609516       NaN  0.609516  0.609516  0.609516   \n",
       "0.750 0.001000        9.0  0.697900  0.020048  0.669878  0.679812  0.708005   \n",
       "      0.004394        6.0  0.694352  0.010525  0.681569  0.686802  0.693118   \n",
       "      0.019307       16.0  0.697783  0.012809  0.668708  0.693373  0.697207   \n",
       "      0.084834       18.0  0.700481  0.012795  0.670866  0.692712  0.703244   \n",
       "      0.372759       31.0  0.704001  0.016532  0.672575  0.690502  0.700693   \n",
       "      1.637894       39.0  0.700479  0.017682  0.659323  0.691699  0.699717   \n",
       "      7.196857       32.0  0.699809  0.020306  0.661055  0.687653  0.699470   \n",
       "      31.622777      27.0  0.707750  0.016892  0.675732  0.696054  0.707129   \n",
       "      138.949549     13.0  0.694726  0.021202  0.651374  0.686788  0.693359   \n",
       "      610.540230      4.0  0.700462  0.011293  0.687362  0.694411  0.700163   \n",
       "      2682.695795     5.0  0.700894  0.012433  0.678676  0.705791  0.706203   \n",
       "1.125 0.001000        7.0  0.764602  0.012237  0.757236  0.758531  0.759809   \n",
       "      0.004394        6.0  0.777013  0.013026  0.765176  0.767659  0.775545   \n",
       "      0.019307        4.0  0.792030  0.004567  0.788618  0.789388  0.790402   \n",
       "      0.084834       19.0  0.784655  0.018792  0.740827  0.781392  0.788342   \n",
       "      0.372759       38.0  0.786210  0.014731  0.754517  0.777411  0.784494   \n",
       "      1.637894       40.0  0.785741  0.014591  0.754877  0.776449  0.785682   \n",
       "      7.196857       28.0  0.781825  0.014449  0.752816  0.774415  0.779885   \n",
       "      31.622777      26.0  0.790781  0.010226  0.770363  0.785133  0.788923   \n",
       "      138.949549     20.0  0.787554  0.018293  0.753575  0.775278  0.790003   \n",
       "      610.540230      9.0  0.783217  0.017300  0.762592  0.775948  0.780088   \n",
       "      11787.686348    1.0  0.790579       NaN  0.790579  0.790579  0.790579   \n",
       "      51794.746792    1.0  0.774319       NaN  0.774319  0.774319  0.774319   \n",
       "      227584.592607   1.0  0.775252       NaN  0.775252  0.775252  0.775252   \n",
       "1.500 0.001000        4.0  0.855553  0.008557  0.849032  0.850285  0.852637   \n",
       "      0.004394        2.0  0.836696  0.004298  0.833657  0.835177  0.836696   \n",
       "      0.019307        1.0  0.832359       NaN  0.832359  0.832359  0.832359   \n",
       "      0.084834       12.0  0.854349  0.010282  0.832575  0.850241  0.854107   \n",
       "      0.372759       44.0  0.852706  0.010611  0.825475  0.846105  0.853751   \n",
       "      1.637894       43.0  0.855124  0.011590  0.832043  0.846238  0.856479   \n",
       "      7.196857       40.0  0.857269  0.012833  0.830886  0.847886  0.858415   \n",
       "      31.622777      20.0  0.856382  0.011398  0.841490  0.847644  0.855714   \n",
       "      138.949549     19.0  0.858096  0.009986  0.841111  0.854616  0.858083   \n",
       "      610.540230     12.0  0.853926  0.010041  0.835048  0.846991  0.855413   \n",
       "      2682.695795     2.0  0.851306  0.001925  0.849945  0.850626  0.851306   \n",
       "      11787.686348    1.0  0.838245       NaN  0.838245  0.838245  0.838245   \n",
       "\n",
       "                                         \n",
       "                          75%       max  \n",
       "param C                                  \n",
       "0.000 0.001000       0.508796  0.528035  \n",
       "      0.004394       0.513394  0.538359  \n",
       "      0.019307       0.514531  0.546536  \n",
       "      0.084834       0.510608  0.540863  \n",
       "      0.372759       0.505587  0.540648  \n",
       "      1.637894       0.518141  0.529839  \n",
       "      7.196857       0.515212  0.531061  \n",
       "      31.622777      0.496646  0.498003  \n",
       "      138.949549     0.494738  0.508580  \n",
       "      610.540230     0.506549  0.511327  \n",
       "      2682.695795    0.497566  0.501755  \n",
       "      51794.746792   0.498608  0.498608  \n",
       "      227584.592607  0.545803  0.545803  \n",
       "0.375 0.001000       0.612808  0.632179  \n",
       "      0.004394       0.606894  0.639479  \n",
       "      0.019307       0.612182  0.641670  \n",
       "      0.084834       0.613764  0.641160  \n",
       "      0.372759       0.612045  0.646583  \n",
       "      1.637894       0.620848  0.643448  \n",
       "      7.196857       0.608600  0.646863  \n",
       "      31.622777      0.609944  0.623456  \n",
       "      138.949549     0.611907  0.632687  \n",
       "      610.540230     0.611349  0.611349  \n",
       "      2682.695795    0.603821  0.630200  \n",
       "      11787.686348   0.604891  0.604891  \n",
       "      51794.746792   0.609516  0.609516  \n",
       "0.750 0.001000       0.716724  0.718199  \n",
       "      0.004394       0.703185  0.707072  \n",
       "      0.019307       0.703383  0.719648  \n",
       "      0.084834       0.708763  0.724190  \n",
       "      0.372759       0.716803  0.736704  \n",
       "      1.637894       0.712613  0.736435  \n",
       "      7.196857       0.714588  0.738425  \n",
       "      31.622777      0.718402  0.738597  \n",
       "      138.949549     0.704150  0.733584  \n",
       "      610.540230     0.706213  0.714161  \n",
       "      2682.695795    0.706439  0.707361  \n",
       "1.125 0.001000       0.763282  0.791540  \n",
       "      0.004394       0.778927  0.800729  \n",
       "      0.019307       0.793045  0.798699  \n",
       "      0.084834       0.796284  0.808542  \n",
       "      0.372759       0.795426  0.820522  \n",
       "      1.637894       0.796912  0.816484  \n",
       "      7.196857       0.792605  0.809134  \n",
       "      31.622777      0.797836  0.813304  \n",
       "      138.949549     0.792839  0.818734  \n",
       "      610.540230     0.787182  0.817098  \n",
       "      11787.686348   0.790579  0.790579  \n",
       "      51794.746792   0.774319  0.774319  \n",
       "      227584.592607  0.775252  0.775252  \n",
       "1.500 0.001000       0.857906  0.867908  \n",
       "      0.004394       0.838216  0.839735  \n",
       "      0.019307       0.832359  0.832359  \n",
       "      0.084834       0.857014  0.872553  \n",
       "      0.372759       0.859748  0.874403  \n",
       "      1.637894       0.864740  0.875084  \n",
       "      7.196857       0.866666  0.883515  \n",
       "      31.622777      0.864025  0.877580  \n",
       "      138.949549     0.865646  0.872432  \n",
       "      610.540230     0.862594  0.865252  \n",
       "      2682.695795    0.851987  0.852667  \n",
       "      11787.686348   0.838245  0.838245  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_rows=None\n",
    "df_result.groupby([\"param\", \"C\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13329d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38",
   "language": "python",
   "name": "py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a3043ce43b8894bffef93d1839881ad472cb7607c1a3c9f1cfc63c042591dd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
