{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "92ac5d68-4055-4066-95c0-a7a5e0a7ca43",
         "metadata": {},
         "source": [
            "# Setup and imports"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "099cd60a",
         "metadata": {},
         "outputs": [],
         "source": [
            "import warnings; warnings.simplefilter('ignore', FutureWarning)\n",
            "import numpy as np\n",
            "import time\n",
            "from copy import deepcopy\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
            "from sklearn.metrics import roc_auc_score, roc_curve\n",
            "from sklearn.model_selection import (permutation_test_score, learning_curve, LeaveOneGroupOut,\n",
            "                                     KFold, cross_val_score, cross_val_predict, cross_validate,\n",
            "                                     train_test_split)\n",
            "from sklearn.utils import parallel_backend\n",
            "from sklearn.base import clone\n",
            "from joblib.parallel import Parallel, delayed\n",
            "from permutation_helpers import random_data_gen, post_hoc_permutation\n",
            "from simulate import simulate\n",
            "from dask.distributed import progress, Client, wait"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "461f0030",
         "metadata": {},
         "source": [
            "## Set up client"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "a3dbe440",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Unique port for jrudoler is 51360\n",
                  "{'dashboard_address': ':51360'}\n",
                  "To view the dashboard, run: \n",
                  "`ssh -fN jrudoler@rhino2.psych.upenn.edu -L 8000:192.168.86.126:51360` in your local computer's terminal (NOT rhino) \n",
                  "and then navigate to localhost:8000 in your browser\n",
                  "You've chosen to scale your cluster manually. This means workers will continue to run until you manually shut them down. Remember to run `client.shutdown` after you're done computing and no longer need to reserve resources.\n"
               ]
            }
         ],
         "source": [
            "# import cmldask.CMLDask as da\n",
            "# client = da.new_dask_client_slurm(\n",
            "#     job_name=\"simulations\",\n",
            "#     memory_per_job=\"2GB\",\n",
            "#     max_n_jobs=400, threads_per_job=1, \n",
            "#     adapt=False,\n",
            "#     local_directory=\"/home1/jrudoler/dask-worker-space\",\n",
            "#     log_directory=\"/home1/jrudoler/logs/\",\n",
            "# )\n",
            "# client = Client()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "51deafed",
         "metadata": {},
         "outputs": [],
         "source": [
            "from dask_jobqueue import SGECluster\n",
            "from dask_jobqueue import SLURMCluster\n",
            "\n",
            "cluster = SLURMCluster(\n",
            "    cores = 10,\n",
            "    memory = \"2GB\",\n",
            "    processes = 1,\n",
            "    log_directory = \"/home1/jrudoler/logs/\",\n",
            "    local_directory = \"/home1/jrudoler/dask-worker-space/\",\n",
            ")\n",
            "\n",
            "# cluster = SGECluster(\n",
            "#         cores=threads_per_job,\n",
            "#         processes=processes_per_job,\n",
            "#         memory=memory_per_job,\n",
            "#         queue=queue,\n",
            "#         walltime=walltime,\n",
            "#         job_name=job_name,\n",
            "#         local_directory=local_directory or os.environ[\"HOME\"] + \"/dask-worker-space/\",\n",
            "#         log_directory=log_directory or os.environ[\"HOME\"],\n",
            "#         scheduler_options=scheduler_options,\n",
            "#         **kwargs,\n",
            "# )\n",
            "\n",
            "client = Client(cluster)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "7465c50f",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<distributed.deploy.adaptive.Adaptive at 0x7f0d362d0bd0>"
                  ]
               },
               "execution_count": 9,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "client.cluster.adapt(maximum_jobs=20)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "cd8ff718",
         "metadata": {},
         "outputs": [],
         "source": [
            "from time import sleep\n",
            "def slow_function(x):\n",
            "    sleep(60)\n",
            "    return x + 1\n",
            "\n",
            "futures = client.map(slow_function, range(1000))\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "17993e54",
         "metadata": {},
         "outputs": [],
         "source": [
            "results = client.gather(futures)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "993416a4",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2024-07-26 14:09:41,409 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
               ]
            }
         ],
         "source": [
            "client.shutdown()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "13e9af3f",
         "metadata": {},
         "source": [
            "# Post-hoc simulations"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "62ad8803",
         "metadata": {},
         "source": [
            "#### Post-hoc simulation parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "id": "3f932880",
         "metadata": {},
         "outputs": [],
         "source": [
            "### shared parameters\n",
            "class_params = {\n",
            "        \"C\":np.logspace(np.log10(1e-4), np.log10(1e5), 8),\n",
            "        \"class_weight\":\"balanced\"\n",
            "    }\n",
            "permutation_params = {\n",
            "        \"n_permutations\": 5000\n",
            "    }\n",
            "sim_params = {\"n_sim\": 500}\n",
            "data_gen_params = {\n",
            "    \"maha\":np.linspace(0., 1.5, 5)[0],\n",
            "    \"psi_diag\": 1.0,\n",
            "    \"psi_offdiag\": 0.,\n",
            "    \"ddof\": 150\n",
            "}\n",
            "samplesize_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"maha\":0.,\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "        \n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "nfeats_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"maha\":0.,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "ratio_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        \"maha\":0.,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "testsize_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "50323c21",
         "metadata": {},
         "source": [
            "#### Simulation functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "id": "8eccfaf9",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n"
               ]
            }
         ],
         "source": [
            "@simulate(**samplesize_params_post[\"sim\"])\n",
            "def simulate_samplesize_post(param=None, seed=None, settings=samplesize_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    return score, permutation_scores, pvalue\n",
            "\n",
            "@simulate(**testsize_params_post[\"sim\"])\n",
            "def simulate_testsize_post(param=None, seed=None, settings=testsize_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    return score, permutation_scores, pvalue\n",
            "\n",
            "@simulate(**nfeats_params_post[\"sim\"])\n",
            "def simulate_nfeats_post(param=None, seed=None, settings=nfeats_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    return score, permutation_scores, pvalue\n",
            "\n",
            "@simulate(**ratio_params_post[\"sim\"])\n",
            "def simulate_ratio_post(param=None, seed=None, settings=ratio_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    return score, permutation_scores, pvalue"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0941b9ea",
         "metadata": {},
         "source": [
            "#### Run functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "c27286a7",
         "metadata": {
            "tags": []
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
            "samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
            "nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
            "ratio_futures_post, ratio_gather = simulate_ratio_post()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9603cac4",
         "metadata": {},
         "source": [
            "#### Gather results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "id": "3d2e6b61",
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "os.makedirs(f\"sim_results/maha_{data_gen_params['maha']:.1f}\", exist_ok=True)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "cdc05025",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(testsize_futures_post)\n",
            "testsize_result = testsize_gather(testsize_futures_post) \n",
            "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = testsize_params_post\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_post.pkl\")\n",
            "client.cancel(testsize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "acbffffd",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(samplesize_futures_post)\n",
            "samplesize_result = samplesize_gather(samplesize_futures_post) \n",
            "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = samplesize_params_post\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_post.pkl\")\n",
            "client.cancel(samplesize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "e5f3154d",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(nfeats_futures_post)\n",
            "nfeats_result = nfeats_gather(nfeats_futures_post)\n",
            "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = nfeats_params_post\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_post.pkl\")\n",
            "client.cancel(nfeats_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "72d7efa0",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(ratio_futures_post)\n",
            "ratio_result = ratio_gather(ratio_futures_post)\n",
            "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = ratio_params_post\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_post.pkl\")\n",
            "client.cancel(ratio_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "7a7b42bc",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(samplesize_futures_post + ratio_futures_post + nfeats_futures_post + testsize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "0c1692d9",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.shutdown()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9aab71d2",
         "metadata": {},
         "source": [
            "# Pre-training permutations (original)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "c8f2519a",
         "metadata": {},
         "outputs": [],
         "source": [
            "def _train_score(estimator, X_train, X_test, y_train, y_test, \n",
            "                score_func, shuffle_labels=False):\n",
            "    if shuffle_labels:\n",
            "        indices = np.random.default_rng().permutation(len(y_train))\n",
            "        y_train = y_train[indices]\n",
            "    estimator.fit(X_train, y_train)\n",
            "    y_pred = estimator.predict_proba(X_test)[:,1]\n",
            "    score = score_func(y_true=y_test, y_score=y_pred)\n",
            "    return score\n",
            "\n",
            "\n",
            "\n",
            "def pre_training_permutation(estimator, X_train, X_test, y_train, y_test,\n",
            "                            n_permutations, score_func, verbose=False, n_jobs=None):\n",
            "    score = _train_score(\n",
            "        clone(estimator), X_train, X_test, y_train, y_test, score_func, shuffle_labels=False\n",
            "    )\n",
            "    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
            "        delayed(_train_score)(\n",
            "            clone(estimator),\n",
            "            X_train, X_test, y_train, y_test,\n",
            "            score_func,\n",
            "            shuffle_labels=True,\n",
            "        )\n",
            "        for _ in range(n_permutations)\n",
            "    )\n",
            "    permutation_scores = np.array(permutation_scores)\n",
            "    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n",
            "    return score, permutation_scores, pvalue"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "835f9fb8",
         "metadata": {},
         "source": [
            "#### Simulation parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "aca895a9",
         "metadata": {},
         "outputs": [],
         "source": [
            "### shared parameters\n",
            "# class_params = {\n",
            "#     \"C\":1e-3,\n",
            "#     \"class_weight\":\"balanced\"\n",
            "# }\n",
            "# permutation_params = {\n",
            "#     \"n_permutations\": 5000\n",
            "# }\n",
            "# sim_params = {\"n_sim\": 150}\n",
            "# data_gen_params = {\n",
            "#     \"maha\":np.linspace(0., 1.5, 5)[0],\n",
            "#     \"psi_diag\": 1.0,\n",
            "#     \"psi_offdiag\": 0.,\n",
            "#     \"ddof\": 150\n",
            "# }\n",
            "samplesize_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "        \n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "nfeats_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "ratio_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "testsize_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "35e8088e",
         "metadata": {},
         "source": [
            "#### Simulation functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "70173f21",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.126:51360/status\n"
               ]
            }
         ],
         "source": [
            "@simulate(**samplesize_params_pre[\"sim\"])\n",
            "def simulate_samplesize_pre(param=None, seed=None, settings=samplesize_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    return score, null, p\n",
            "\n",
            "@simulate(**testsize_params_pre[\"sim\"])\n",
            "def simulate_testsize_pre(param=None, seed=None, settings=testsize_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    return score, null, p\n",
            "\n",
            "@simulate(**nfeats_params_pre[\"sim\"])\n",
            "def simulate_nfeats_pre(param=None, seed=None, settings=nfeats_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    return score, null, p\n",
            "\n",
            "@simulate(**ratio_params_pre[\"sim\"])\n",
            "def simulate_ratio_pre(param=None, seed=None, settings=ratio_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    return score, null, p"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "738a79c1-efce-4a4f-a46b-882d3e200d8f",
         "metadata": {},
         "source": [
            "#### Run functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "f2e26d45",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
            "samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
            "nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
            "ratio_futures_pre, ratio_gather = simulate_ratio_pre()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bc558269-d70f-4bd0-9822-d9538850297b",
         "metadata": {},
         "source": [
            "#### Gather results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "65445e15",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(testsize_futures_pre)\n",
            "testsize_result = testsize_gather(testsize_futures_pre) \n",
            "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = testsize_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_pre.pkl\")\n",
            "client.cancel(testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "754db625",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(samplesize_futures_pre)\n",
            "samplesize_result = samplesize_gather(samplesize_futures_pre) \n",
            "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = samplesize_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_pre.pkl\")\n",
            "client.cancel(samplesize_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3fe27f0a",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(nfeats_futures_pre)\n",
            "nfeats_result = nfeats_gather(nfeats_futures_pre)\n",
            "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = nfeats_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_pre.pkl\")\n",
            "client.cancel(nfeats_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b57a045d",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(ratio_futures_pre)\n",
            "ratio_result = ratio_gather(ratio_futures_pre)\n",
            "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result._metadata = ratio_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_pre.pkl\")\n",
            "client.cancel(ratio_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "id": "5de0fbdf",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(ratio_futures_pre+nfeats_futures_pre+samplesize_futures_pre+testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c87e3da1-4763-4dd5-bf3a-846bd26be597",
         "metadata": {},
         "source": [
            "# Comparing runtime"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "id": "ae17d012-36db-417d-b027-95e1e1da0b34",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n"
               ]
            }
         ],
         "source": [
            "runtime_params = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_pre(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    stop = time.time()\n",
            "    return stop - start\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_post(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## train model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    estimator.fit(X=X_train, y=y_train)\n",
            "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    stop = time.time()\n",
            "    return stop - start"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "id": "c0ef8706-3676-4d6e-a650-34eb85eb7f44",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "runtime_futures_pre, runtime_gather = simulate_runtime_pre()\n",
            "runtime_futures_post, runtime_gather = simulate_runtime_post()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "id": "d57fba68-910f-4e9c-80f2-3182889f597b",
         "metadata": {},
         "outputs": [],
         "source": [
            "runtime_result_pre = runtime_gather(runtime_futures_pre)\n",
            "runtime_result_post = runtime_gather(runtime_futures_post)\n",
            "df_result_pre = pd.DataFrame(runtime_result_pre).melt(var_name=\"param\")\n",
            "df_result_post = pd.DataFrame(runtime_result_post).melt(var_name=\"param\")\n",
            "df_result_pre['test'] = 'pre'\n",
            "df_result_post['test'] = 'post'\n",
            "df_result = pd.concat([df_result_pre, df_result_post])\n",
            "df_result._metadata = runtime_params\n",
            "df_result.to_pickle(f\"sim_results/simulate_runtime.pkl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "13329d27",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "permutation-tests-aQMIHBsu-py3.11",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.3"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
