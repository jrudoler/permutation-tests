{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "92ac5d68-4055-4066-95c0-a7a5e0a7ca43",
         "metadata": {},
         "source": [
            "# Setup and imports"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "099cd60a",
         "metadata": {},
         "outputs": [],
         "source": [
            "import warnings; warnings.simplefilter('ignore', FutureWarning)\n",
            "import numpy as np\n",
            "import time\n",
            "import os\n",
            "from copy import deepcopy\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
            "from sklearn.metrics import roc_auc_score, roc_curve\n",
            "from sklearn.model_selection import (permutation_test_score, learning_curve, LeaveOneGroupOut,\n",
            "                                     KFold, cross_val_score, cross_val_predict, cross_validate,\n",
            "                                     train_test_split)\n",
            "from sklearn.utils import parallel_backend\n",
            "from sklearn.base import clone\n",
            "import pickle\n",
            "from joblib.parallel import Parallel, delayed\n",
            "from permutation_helpers import *\n",
            "from simulate import simulate\n",
            "from dask.distributed import progress, Client, wait"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "461f0030",
         "metadata": {},
         "source": [
            "## Set up client"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "a3dbe440",
         "metadata": {},
         "outputs": [],
         "source": [
            "# import cmldask.CMLDask as da\n",
            "# client = da.new_dask_client_slurm(\n",
            "#     job_name=\"simulations\",\n",
            "#     memory_per_job=\"2GB\",\n",
            "#     max_n_jobs=400, threads_per_job=1, \n",
            "#     adapt=False,\n",
            "#     local_directory=\"/home1/jrudoler/dask-worker-space\",\n",
            "#     log_directory=\"/home1/jrudoler/logs/\",\n",
            "# )\n",
            "# client = Client()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "51deafed",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<distributed.deploy.adaptive.Adaptive at 0x7fb1fb6d0ad0>"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "# from dask_jobqueue import SGECluster\n",
            "from dask_jobqueue import SLURMCluster\n",
            "\n",
            "cluster = SLURMCluster(\n",
            "    cores = 4, # threads per job\n",
            "    memory = \"2GB\",\n",
            "    processes = 1,\n",
            "    log_directory = os.path.join(os.environ[\"HOME\"], \"logs/\"),\n",
            "    local_directory = os.path.join(os.environ[\"HOME\"], \"dask-worker-space/\"),\n",
            "    walltime = \"7-00:00:00\",\n",
            "    name = \"permutations\"\n",
            ")\n",
            "\n",
            "# cluster = SGECluster(\n",
            "#         cores=threads_per_job,\n",
            "#         processes=processes_per_job,\n",
            "#         memory=memory_per_job,\n",
            "#         queue=queue,\n",
            "#         walltime=walltime,\n",
            "#         job_name=job_name,\n",
            "#         local_directory=local_directory or os.environ[\"HOME\"] + \"/dask-worker-space/\",\n",
            "#         log_directory=log_directory or os.environ[\"HOME\"],\n",
            "#         scheduler_options=scheduler_options,\n",
            "#         **kwargs,\n",
            "# )\n",
            "\n",
            "client = Client(cluster)\n",
            "cluster.adapt(maximum_jobs=200)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "993416a4",
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "2024-07-26 14:09:41,409 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
               ]
            }
         ],
         "source": [
            "client.shutdown()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "13e9af3f",
         "metadata": {},
         "source": [
            "# Post-hoc simulations"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "62ad8803",
         "metadata": {},
         "source": [
            "#### Post-hoc simulation parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "3f932880",
         "metadata": {},
         "outputs": [],
         "source": [
            "### shared parameters\n",
            "class_params = {\n",
            "        \"C\":np.logspace(np.log10(1e-4), np.log10(1e5), 8),\n",
            "        \"class_weight\":\"balanced\"\n",
            "    }\n",
            "permutation_params = {\n",
            "        \"n_permutations\": 5000\n",
            "    }\n",
            "sim_params = {\n",
            "    \"n_sim\": 500,\n",
            "    }\n",
            "file_params = {\n",
            "    \"save\": True,\n",
            "}\n",
            "data_gen_params = {\n",
            "    \"maha\":np.linspace(0., 1.5, 5)[0],\n",
            "    \"psi_diag\": 1.0,\n",
            "    \"psi_offdiag\": 0.,\n",
            "    \"ddof\": 150\n",
            "}\n",
            "\n",
            "## set up directories for saving results\n",
            "\n",
            "## results are separated by the the underlying probability distributions (and their mahalanobis distance)\n",
            "\n",
            "import os\n",
            "data_dir = os.path.join(os.environ[\"HOME\"], \"data\")\n",
            "results_dir = os.path.join(data_dir, \"sim_results\", f\"maha_{data_gen_params['maha']:.1f}\")\n",
            "os.makedirs(results_dir, exist_ok=True) \n",
            "file_params[\"results_dir\"] = results_dir\n",
            "\n",
            "## set up parameters for specific simulations\n",
            "\n",
            "samplesize_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"maha\":0.,\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "        \n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "nfeats_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"maha\":0.,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "ratio_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        \"maha\":0.,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "testsize_params_post = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "50323c21",
         "metadata": {},
         "source": [
            "#### Simulation functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "38b9c1e1",
         "metadata": {},
         "outputs": [],
         "source": [
            "from sklearn.metrics import roc_auc_score, accuracy_score, log_loss, brier_score_loss\n",
            "def score_model(y_true, y_pred):\n",
            "    \"\"\"\n",
            "    Compute performance metrics based on given predictions (output from predict_proba)\n",
            "      and labels. \n",
            "    Returns a dictionary with the following metrics:\n",
            "    - roc_auc\n",
            "    - accuracy\n",
            "    - log_loss\n",
            "    - brier_score\n",
            "    \"\"\"\n",
            "    # predictions are 1 if the probability of the positive class is greater than 0.5\n",
            "    y_pred_proba = np.array(y_pred)\n",
            "    y_pred_disc = (y_pred_proba > 0.5).astype(int)\n",
            "    # compute metrics\n",
            "    roc_auc = float(roc_auc_score(y_true, y_pred_proba))\n",
            "    accuracy = float(accuracy_score(y_true, y_pred_disc))\n",
            "    logloss = float(log_loss(y_true, y_pred_proba))\n",
            "    brier_score = float(brier_score_loss(y_true, y_pred_proba, pos_label=1))\n",
            "    return {\"roc_auc\":roc_auc, \"accuracy\":accuracy, \"log_loss\":logloss, \"brier_score\":brier_score}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "8eccfaf9",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n"
               ]
            }
         ],
         "source": [
            "@simulate(**samplesize_params_post[\"sim\"])\n",
            "def simulate_samplesize_post(param=None, seed=None, simno=None, settings=samplesize_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(\n",
            "        X, y, test_size=0.2, shuffle=True\n",
            "    )\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = post_hoc_permutation(\n",
            "        y_true=y_test,\n",
            "        y_score=y_pred,\n",
            "        n_permutations=n_permutations,\n",
            "        score_function=score_model,\n",
            "        n_jobs=-1,\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"samplesize_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "\n",
            "@simulate(**testsize_params_post[\"sim\"])\n",
            "def simulate_testsize_post(param=None, seed=None, simno=None, settings=testsize_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(\n",
            "        X, y, test_size=param, shuffle=True\n",
            "    )\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = post_hoc_permutation(\n",
            "        y_true=y_test,\n",
            "        y_score=y_pred,\n",
            "        n_permutations=n_permutations,\n",
            "        score_function=score_model,\n",
            "        n_jobs=-1,\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"testsize_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "\n",
            "@simulate(**nfeats_params_post[\"sim\"])\n",
            "def simulate_nfeats_post(param=None, seed=None, simno=None, settings=nfeats_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(\n",
            "        X, y, test_size=0.2, shuffle=True\n",
            "    )\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = post_hoc_permutation(\n",
            "        y_true=y_test,\n",
            "        y_score=y_pred,\n",
            "        n_permutations=n_permutations,\n",
            "        score_function=score_model,\n",
            "        n_jobs=-1,\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"nfeats_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "\n",
            "@simulate(**ratio_params_post[\"sim\"])\n",
            "def simulate_ratio_post(param=None, seed=None, simno=None, settings=ratio_params_post):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(\n",
            "        X, y, test_size=0.2, shuffle=True\n",
            "    )\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_estimator = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_estimator = estimator\n",
            "    ## use model with tuned penalty\n",
            "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = post_hoc_permutation(\n",
            "        y_true=y_test,\n",
            "        y_score=y_pred,\n",
            "        n_permutations=n_permutations,\n",
            "        score_function=score_model,\n",
            "        n_jobs=-1,\n",
            "    )\n",
            "    # save with pickle\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"ratio_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "0941b9ea",
         "metadata": {},
         "source": [
            "#### Run functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "id": "c27286a7",
         "metadata": {
            "tags": []
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
            "samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
            "nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
            "ratio_futures_post, ratio_gather = simulate_ratio_post()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9603cac4",
         "metadata": {},
         "source": [
            "#### Gather results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "cdc05025",
         "metadata": {},
         "outputs": [
            {
               "ename": "",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
                  "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
                  "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
                  "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
               ]
            }
         ],
         "source": [
            "wait(testsize_futures_post)\n",
            "testsize_result = testsize_gather(testsize_futures_post) \n",
            "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
            "del testsize_result\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = testsize_params_post\n",
            "df_result.to_pickle(os.path.join(results_dir, \"simulate_testsize_post.pkl\"))\n",
            "client.cancel(testsize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "f46fe622",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>simno</th>\n",
                     "      <th>param</th>\n",
                     "      <th>value</th>\n",
                     "      <th>score</th>\n",
                     "      <th>perm_scores</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.01</td>\n",
                     "      <td>({'roc_auc': 0.5238095238095238, 'accuracy': 0...</td>\n",
                     "      <td>{'roc_auc': 0.5238095238095238, 'accuracy': 0....</td>\n",
                     "      <td>[{'roc_auc': 0.8571428571428571, 'accuracy': 0...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>1</td>\n",
                     "      <td>0.01</td>\n",
                     "      <td>({'roc_auc': 0.6190476190476191, 'accuracy': 0...</td>\n",
                     "      <td>{'roc_auc': 0.6190476190476191, 'accuracy': 0....</td>\n",
                     "      <td>[{'roc_auc': 0.7142857142857143, 'accuracy': 0...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>2</td>\n",
                     "      <td>0.01</td>\n",
                     "      <td>({'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss...</td>\n",
                     "      <td>{'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss'...</td>\n",
                     "      <td>[{'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>3</td>\n",
                     "      <td>0.01</td>\n",
                     "      <td>({'roc_auc': 0.39999999999999997, 'accuracy': ...</td>\n",
                     "      <td>{'roc_auc': 0.39999999999999997, 'accuracy': 0...</td>\n",
                     "      <td>[{'roc_auc': 0.68, 'accuracy': 0.7, 'log_loss'...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.01</td>\n",
                     "      <td>({'roc_auc': 0.5, 'accuracy': 0.6, 'log_loss':...</td>\n",
                     "      <td>{'roc_auc': 0.5, 'accuracy': 0.6, 'log_loss': ...</td>\n",
                     "      <td>[{'roc_auc': 0.41666666666666663, 'accuracy': ...</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "   simno  param                                              value  \\\n",
                     "0      0   0.01  ({'roc_auc': 0.5238095238095238, 'accuracy': 0...   \n",
                     "1      1   0.01  ({'roc_auc': 0.6190476190476191, 'accuracy': 0...   \n",
                     "2      2   0.01  ({'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss...   \n",
                     "3      3   0.01  ({'roc_auc': 0.39999999999999997, 'accuracy': ...   \n",
                     "4      4   0.01  ({'roc_auc': 0.5, 'accuracy': 0.6, 'log_loss':...   \n",
                     "\n",
                     "                                               score  \\\n",
                     "0  {'roc_auc': 0.5238095238095238, 'accuracy': 0....   \n",
                     "1  {'roc_auc': 0.6190476190476191, 'accuracy': 0....   \n",
                     "2  {'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss'...   \n",
                     "3  {'roc_auc': 0.39999999999999997, 'accuracy': 0...   \n",
                     "4  {'roc_auc': 0.5, 'accuracy': 0.6, 'log_loss': ...   \n",
                     "\n",
                     "                                         perm_scores  \n",
                     "0  [{'roc_auc': 0.8571428571428571, 'accuracy': 0...  \n",
                     "1  [{'roc_auc': 0.7142857142857143, 'accuracy': 0...  \n",
                     "2  [{'roc_auc': 0.625, 'accuracy': 0.6, 'log_loss...  \n",
                     "3  [{'roc_auc': 0.68, 'accuracy': 0.7, 'log_loss'...  \n",
                     "4  [{'roc_auc': 0.41666666666666663, 'accuracy': ...  "
                  ]
               },
               "execution_count": 24,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sample = df_result.head()\n",
            "sample"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "id": "d29b682f",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>null_roc_auc</th>\n",
                     "      <th>null_accuracy</th>\n",
                     "      <th>null_log_loss</th>\n",
                     "      <th>null_brier_score</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.857143</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.649343</td>\n",
                     "      <td>0.228244</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.809524</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.653256</td>\n",
                     "      <td>0.230198</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.666667</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.675855</td>\n",
                     "      <td>0.241419</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.809524</td>\n",
                     "      <td>0.8</td>\n",
                     "      <td>0.654911</td>\n",
                     "      <td>0.230961</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0.142857</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.741383</td>\n",
                     "      <td>0.273931</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.250000</td>\n",
                     "      <td>0.2</td>\n",
                     "      <td>0.718917</td>\n",
                     "      <td>0.262813</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.208333</td>\n",
                     "      <td>0.2</td>\n",
                     "      <td>0.710482</td>\n",
                     "      <td>0.258700</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.458333</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.694452</td>\n",
                     "      <td>0.250695</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.500000</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684797</td>\n",
                     "      <td>0.245874</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0.583333</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.676584</td>\n",
                     "      <td>0.241778</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>25000 rows × 4 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "    null_roc_auc  null_accuracy  null_log_loss  null_brier_score\n",
                     "0       0.857143            0.6       0.649343          0.228244\n",
                     "0       0.809524            0.6       0.653256          0.230198\n",
                     "0       0.666667            0.6       0.675855          0.241419\n",
                     "0       0.809524            0.8       0.654911          0.230961\n",
                     "0       0.142857            0.4       0.741383          0.273931\n",
                     "..           ...            ...            ...               ...\n",
                     "4       0.250000            0.2       0.718917          0.262813\n",
                     "4       0.208333            0.2       0.710482          0.258700\n",
                     "4       0.458333            0.4       0.694452          0.250695\n",
                     "4       0.500000            0.4       0.684797          0.245874\n",
                     "4       0.583333            0.6       0.676584          0.241778\n",
                     "\n",
                     "[25000 rows x 4 columns]"
                  ]
               },
               "execution_count": 33,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "sample[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 36,
         "id": "3707e29b",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>simno</th>\n",
                     "      <th>roc_auc</th>\n",
                     "      <th>accuracy</th>\n",
                     "      <th>log_loss</th>\n",
                     "      <th>brier_score</th>\n",
                     "      <th>null_roc_auc</th>\n",
                     "      <th>null_accuracy</th>\n",
                     "      <th>null_log_loss</th>\n",
                     "      <th>null_brier_score</th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.52381</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684997</td>\n",
                     "      <td>0.246022</td>\n",
                     "      <td>0.857143</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.649343</td>\n",
                     "      <td>0.228244</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.52381</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684997</td>\n",
                     "      <td>0.246022</td>\n",
                     "      <td>0.809524</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.653256</td>\n",
                     "      <td>0.230198</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.52381</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684997</td>\n",
                     "      <td>0.246022</td>\n",
                     "      <td>0.666667</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.675855</td>\n",
                     "      <td>0.241419</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.52381</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684997</td>\n",
                     "      <td>0.246022</td>\n",
                     "      <td>0.809524</td>\n",
                     "      <td>0.8</td>\n",
                     "      <td>0.654911</td>\n",
                     "      <td>0.230961</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>0</td>\n",
                     "      <td>0.52381</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684997</td>\n",
                     "      <td>0.246022</td>\n",
                     "      <td>0.142857</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.741383</td>\n",
                     "      <td>0.273931</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>24995</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.50000</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.681027</td>\n",
                     "      <td>0.243995</td>\n",
                     "      <td>0.250000</td>\n",
                     "      <td>0.2</td>\n",
                     "      <td>0.718917</td>\n",
                     "      <td>0.262813</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>24996</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.50000</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.681027</td>\n",
                     "      <td>0.243995</td>\n",
                     "      <td>0.208333</td>\n",
                     "      <td>0.2</td>\n",
                     "      <td>0.710482</td>\n",
                     "      <td>0.258700</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>24997</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.50000</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.681027</td>\n",
                     "      <td>0.243995</td>\n",
                     "      <td>0.458333</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.694452</td>\n",
                     "      <td>0.250695</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>24998</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.50000</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.681027</td>\n",
                     "      <td>0.243995</td>\n",
                     "      <td>0.500000</td>\n",
                     "      <td>0.4</td>\n",
                     "      <td>0.684797</td>\n",
                     "      <td>0.245874</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>24999</th>\n",
                     "      <td>4</td>\n",
                     "      <td>0.50000</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.681027</td>\n",
                     "      <td>0.243995</td>\n",
                     "      <td>0.583333</td>\n",
                     "      <td>0.6</td>\n",
                     "      <td>0.676584</td>\n",
                     "      <td>0.241778</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>25000 rows × 9 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "       simno  roc_auc  accuracy  log_loss  brier_score  null_roc_auc  \\\n",
                     "0          0  0.52381       0.4  0.684997     0.246022      0.857143   \n",
                     "1          0  0.52381       0.4  0.684997     0.246022      0.809524   \n",
                     "2          0  0.52381       0.4  0.684997     0.246022      0.666667   \n",
                     "3          0  0.52381       0.4  0.684997     0.246022      0.809524   \n",
                     "4          0  0.52381       0.4  0.684997     0.246022      0.142857   \n",
                     "...      ...      ...       ...       ...          ...           ...   \n",
                     "24995      4  0.50000       0.6  0.681027     0.243995      0.250000   \n",
                     "24996      4  0.50000       0.6  0.681027     0.243995      0.208333   \n",
                     "24997      4  0.50000       0.6  0.681027     0.243995      0.458333   \n",
                     "24998      4  0.50000       0.6  0.681027     0.243995      0.500000   \n",
                     "24999      4  0.50000       0.6  0.681027     0.243995      0.583333   \n",
                     "\n",
                     "       null_accuracy  null_log_loss  null_brier_score  \n",
                     "0                0.6       0.649343          0.228244  \n",
                     "1                0.6       0.653256          0.230198  \n",
                     "2                0.6       0.675855          0.241419  \n",
                     "3                0.8       0.654911          0.230961  \n",
                     "4                0.4       0.741383          0.273931  \n",
                     "...              ...            ...               ...  \n",
                     "24995            0.2       0.718917          0.262813  \n",
                     "24996            0.2       0.710482          0.258700  \n",
                     "24997            0.4       0.694452          0.250695  \n",
                     "24998            0.4       0.684797          0.245874  \n",
                     "24999            0.6       0.676584          0.241778  \n",
                     "\n",
                     "[25000 rows x 9 columns]"
                  ]
               },
               "execution_count": 36,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pd.merge(\n",
            "    sample[\"score\"].apply(pd.Series),\n",
            "    sample[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "acbffffd",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(samplesize_futures_post)\n",
            "samplesize_result = samplesize_gather(samplesize_futures_post) \n",
            "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
            "del samplesize_result\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = samplesize_params_post\n",
            "df_result.to_pickle(os.path.join(results_dir,\"simulate_samplesize_post.pkl\"))\n",
            "client.cancel(samplesize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "e5f3154d",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(nfeats_futures_post)\n",
            "nfeats_result = nfeats_gather(nfeats_futures_post)\n",
            "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
            "del nfeats_result\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = nfeats_params_post\n",
            "df_result.to_pickle(os.path.join(results_dir, \"simulate_nfeats_post.pkl\"))\n",
            "client.cancel(nfeats_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "72d7efa0",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(ratio_futures_post)\n",
            "ratio_result = ratio_gather(ratio_futures_post)\n",
            "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
            "del ratio_result\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = ratio_params_post\n",
            "df_result.to_pickle(os.path.join(results_dir, \"simulate_ratio_post.pkl\"))\n",
            "client.cancel(ratio_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 19,
         "id": "7a7b42bc",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(samplesize_futures_post + ratio_futures_post + nfeats_futures_post + testsize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "id": "0c1692d9",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.shutdown()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9aab71d2",
         "metadata": {},
         "source": [
            "# Pre-training permutations (original)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "835f9fb8",
         "metadata": {},
         "source": [
            "#### Simulation parameters"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "id": "aca895a9",
         "metadata": {},
         "outputs": [],
         "source": [
            "### shared parameters\n",
            "# class_params = {\n",
            "#     \"C\":1e-3,\n",
            "#     \"class_weight\":\"balanced\"\n",
            "# }\n",
            "# permutation_params = {\n",
            "#     \"n_permutations\": 5000\n",
            "# }\n",
            "# sim_params = {\"n_sim\": 150}\n",
            "# data_gen_params = {\n",
            "#     \"maha\":np.linspace(0., 1.5, 5)[0],\n",
            "#     \"psi_diag\": 1.0,\n",
            "#     \"psi_offdiag\": 0.,\n",
            "#     \"ddof\": 150\n",
            "# }\n",
            "samplesize_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "        \n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "nfeats_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "ratio_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}\n",
            "\n",
            "testsize_params_pre = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params,\n",
            "    \"file\": file_params\n",
            "}"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "35e8088e",
         "metadata": {},
         "source": [
            "#### Simulation functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "id": "70173f21",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.107:8787/status\n"
               ]
            }
         ],
         "source": [
            "@simulate(**samplesize_params_pre[\"sim\"])\n",
            "def simulate_samplesize_pre(param=None, seed=None, simno=None, settings=samplesize_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_samplesize_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "@simulate(**testsize_params_pre[\"sim\"])\n",
            "def simulate_testsize_pre(param=None, seed=None, simno=None, settings=testsize_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_testsize_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "@simulate(**nfeats_params_pre[\"sim\"])\n",
            "def simulate_nfeats_pre(param=None, seed=None, simno=None, settings=nfeats_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_nfeats_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores\n",
            "\n",
            "@simulate(**ratio_params_pre[\"sim\"])\n",
            "def simulate_ratio_pre(param=None, seed=None, simno=None, settings=ratio_params_pre):\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set\n",
            "    X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        if AUC >= max_AUC:\n",
            "            max_AUC = AUC\n",
            "            best_C = C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    if settings[\"file\"][\"save\"]:\n",
            "        pickle.dump(\n",
            "            (score, permutation_scores), \n",
            "            open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_ratio_{param:.4f}_simno_{simno}.pkl\"), \"wb\"))\n",
            "    return score, permutation_scores"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "738a79c1-efce-4a4f-a46b-882d3e200d8f",
         "metadata": {},
         "source": [
            "#### Run functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "id": "f2e26d45",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
            "samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
            "nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
            "ratio_futures_pre, ratio_gather = simulate_ratio_pre()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bc558269-d70f-4bd0-9822-d9538850297b",
         "metadata": {},
         "source": [
            "#### Gather results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "65445e15",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(testsize_futures_pre)\n",
            "testsize_result = testsize_gather(testsize_futures_pre) \n",
            "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = testsize_params_pre\n",
            "\n",
            "df_result.to_pickle(os.path.join(results_dir, \"simulate_testsize_pre.pkl\"))\n",
            "client.cancel(testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "754db625",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(samplesize_futures_pre)\n",
            "samplesize_result = samplesize_gather(samplesize_futures_pre) \n",
            "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = samplesize_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_pre.pkl\")\n",
            "client.cancel(samplesize_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "3fe27f0a",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(nfeats_futures_pre)\n",
            "nfeats_result = nfeats_gather(nfeats_futures_pre)\n",
            "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = nfeats_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_pre.pkl\")\n",
            "client.cancel(nfeats_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "b57a045d",
         "metadata": {},
         "outputs": [],
         "source": [
            "wait(ratio_futures_pre)\n",
            "ratio_result = ratio_gather(ratio_futures_pre)\n",
            "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
            "df_result[[\"score\", \"perm_scores\"]] = df_result['value'].apply(pd.Series)\n",
            "df_result = df_result.drop(columns='value')\n",
            "df_result = pd.merge(\n",
            "    df_result[\"score\"].apply(pd.Series),\n",
            "    df_result[\"perm_scores\"].explode().apply(pd.Series).add_prefix(\"null_\"),\n",
            "    left_index=True,\n",
            "    right_index=True,\n",
            ").reset_index(names=\"simno\")\n",
            "df_result._metadata = ratio_params_pre\n",
            "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_pre.pkl\")\n",
            "client.cancel(ratio_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 33,
         "id": "5de0fbdf",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(ratio_futures_pre+nfeats_futures_pre+samplesize_futures_pre+testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c87e3da1-4763-4dd5-bf3a-846bd26be597",
         "metadata": {},
         "source": [
            "# Comparing runtime"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "id": "ae17d012-36db-417d-b027-95e1e1da0b34",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n"
               ]
            }
         ],
         "source": [
            "runtime_params = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_pre(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    stop = time.time()\n",
            "    return stop - start\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_post(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## train model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    estimator.fit(X=X_train, y=y_train)\n",
            "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    stop = time.time()\n",
            "    return stop - start"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "id": "c0ef8706-3676-4d6e-a650-34eb85eb7f44",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "runtime_futures_pre, runtime_gather = simulate_runtime_pre()\n",
            "runtime_futures_post, runtime_gather = simulate_runtime_post()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "id": "d57fba68-910f-4e9c-80f2-3182889f597b",
         "metadata": {},
         "outputs": [],
         "source": [
            "runtime_result_pre = runtime_gather(runtime_futures_pre)\n",
            "runtime_result_post = runtime_gather(runtime_futures_post)\n",
            "df_result_pre = pd.DataFrame(runtime_result_pre).melt(var_name=\"param\")\n",
            "df_result_post = pd.DataFrame(runtime_result_post).melt(var_name=\"param\")\n",
            "df_result_pre['test'] = 'pre'\n",
            "df_result_post['test'] = 'post'\n",
            "df_result = pd.concat([df_result_pre, df_result_post])\n",
            "df_result._metadata = runtime_params\n",
            "df_result.to_pickle(f\"sim_results/simulate_runtime.pkl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "13329d27",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "permutation-tests-aQMIHBsu-py3.11",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.3"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
