{
   "cells": [
      {
         "cell_type": "markdown",
         "id": "92ac5d68-4055-4066-95c0-a7a5e0a7ca43",
         "metadata": {},
         "source": [
            "# Setup and imports"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 1,
         "id": "099cd60a",
         "metadata": {},
         "outputs": [],
         "source": [
            "import warnings; warnings.simplefilter('ignore', FutureWarning)\n",
            "import numpy as np\n",
            "import time\n",
            "import os\n",
            "from copy import deepcopy\n",
            "import pandas as pd\n",
            "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
            "from sklearn.metrics import roc_auc_score, roc_curve\n",
            "from sklearn.model_selection import (permutation_test_score, learning_curve, LeaveOneGroupOut,\n",
            "                                     KFold, cross_val_score, cross_val_predict, cross_validate,\n",
            "                                     train_test_split)\n",
            "from sklearn.utils import parallel_backend\n",
            "from sklearn.base import clone\n",
            "import pickle\n",
            "from joblib.parallel import Parallel, delayed\n",
            "from permutation_helpers import *\n",
            "from simulate import simulate\n",
            "\n",
            "# Dask imports\n",
            "from dask.distributed import progress, Client, wait, Future\n",
            "from dask_jobqueue import SGECluster\n",
            "# from dask_jobqueue import SLURMCluster\n",
            "\n",
            "# helpful functions for debugging and monitoring Dask jobs\n",
            "def get_exceptions(futures: Iterable[Future], params: Iterable = None) -> pd.DataFrame:\n",
            "    \"\"\"\n",
            "    Given a list of Dask futures and a list of parameters,\n",
            "    return a DataFrame of exceptions.\n",
            "    \"\"\"\n",
            "    if params is None:\n",
            "        params = range(len(futures))\n",
            "    exceptions = []\n",
            "    for i, (param, future) in enumerate(zip(params, futures)):\n",
            "        if future.status == \"error\":\n",
            "            exceptions.append(pd.Series(\n",
            "                {\n",
            "                    \"param\": param,\n",
            "                    \"exception\": repr(future.exception()),\n",
            "                    \"traceback_obj\": future.traceback(),\n",
            "                }\n",
            "            ))\n",
            "    if not len(exceptions):\n",
            "        raise Exception(\"None of the given futures resulted in exceptions\")\n",
            "    exceptions = pd.concat(exceptions, axis=1).T\n",
            "    exceptions.set_index(\"param\", inplace=True)\n",
            "    return exceptions\n",
            "\n",
            "import traceback\n",
            "def print_traceback(error_df, index):\n",
            "    traceback.print_tb(error_df.loc[index, \"traceback_obj\"])"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "461f0030",
         "metadata": {},
         "source": [
            "## Set up client"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "id": "51deafed",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<distributed.deploy.adaptive.Adaptive at 0x148e3b964950>"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "cluster = SGECluster( # or replace with SLURMCluster or other\n",
            "    cores = 4, # threads per job\n",
            "    memory = \"2GB\",\n",
            "    processes = 1,\n",
            "    log_directory = os.path.join(os.environ[\"HOME\"], \"logs/\"),\n",
            "    local_directory = os.path.join(os.environ[\"HOME\"], \"dask-worker-space/\"),\n",
            "    walltime = \"06:00:00\",\n",
            "    name = \"permutations\"\n",
            ")\n",
            "\n",
            "client = Client(cluster)\n",
            "cluster.adapt(maximum_jobs=100)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "id": "e6dbe270",
         "metadata": {},
         "outputs": [],
         "source": [
            "maha_values = np.linspace(0., 1.5, 5)\n",
            "\n",
            "def set_params(maha, save=True): \n",
            "    ### shared parameters\n",
            "    class_params = {\n",
            "            \"C\":np.logspace(np.log10(1e-4), np.log10(1e5), 8),\n",
            "            \"class_weight\":\"balanced\"\n",
            "        }\n",
            "    permutation_params = {\n",
            "            \"n_permutations\": 5000\n",
            "        }\n",
            "    sim_params = {\n",
            "        \"n_sim\": 500,\n",
            "        }\n",
            "    \n",
            "    data_dir = os.path.join(os.environ[\"HOME\"], \"data\")\n",
            "    results_dir = os.path.join(data_dir, \"sim_results\", f\"maha_{maha:.1f}\")\n",
            "    file_params = {\n",
            "        \"save\": True,\n",
            "        \"results_dir\": results_dir\n",
            "    }\n",
            "    data_gen_params = {\n",
            "        \"maha\": maha,\n",
            "        \"psi_diag\": 1.0,\n",
            "        \"psi_offdiag\": 0.,\n",
            "        \"ddof\": 150,\n",
            "        \"n_samples\":1000,\n",
            "        \"n_feats\": 10,\n",
            "        \"class_ratio\": 0.5,\n",
            "    }\n",
            "    ## default parameters for simulations\n",
            "    default_params ={\n",
            "        \"sim\" : deepcopy(sim_params),\n",
            "        \"data_gen\" : deepcopy(data_gen_params),\n",
            "        \"classif\" : deepcopy(class_params),\n",
            "        \"perm\" : deepcopy(permutation_params),\n",
            "        \"file\" : deepcopy(file_params)\n",
            "    }\n",
            "\n",
            "    ## set up parameters for specific simulations\n",
            "    ## use default parameters and update the ones that need to be changed\n",
            "    ## for each simulation, we will vary one parameter at a time and remove \n",
            "    ## the corresponding key from the data_gen dictionary to avoid conflicts\n",
            "\n",
            "    samplesize_params = deepcopy(default_params)\n",
            "    samplesize_params[\"sim\"][\"parameter_range\"] = np.logspace(2, 5, 5).astype(int)\n",
            "    samplesize_params[\"data_gen\"].pop(\"n_samples\")\n",
            "\n",
            "    nfeats_params = deepcopy(default_params)\n",
            "    nfeats_params[\"sim\"][\"parameter_range\"] = np.logspace(1, 10, 5, base=2).astype(int)\n",
            "    nfeats_params[\"data_gen\"].pop(\"n_feats\")\n",
            "\n",
            "    ratio_params = deepcopy(default_params)\n",
            "    ratio_params[\"sim\"][\"parameter_range\"] = np.logspace(np.log10(.01), np.log10(.5), 5)\n",
            "    ratio_params[\"data_gen\"].pop(\"class_ratio\")\n",
            "\n",
            "    testsize_params = deepcopy(default_params)\n",
            "    testsize_params[\"sim\"][\"parameter_range\"] = np.logspace(np.log10(.01), np.log10(.5), 5)\n",
            "    if save:\n",
            "        pickle.dump(samplesize_params, \n",
            "                    open(f\"settings/samplesize_params_maha_{data_gen_params['maha']:.1f}.pkl\", \"wb\"))\n",
            "        pickle.dump(nfeats_params,\n",
            "                    open(f\"settings/nfeats_params_maha_{data_gen_params['maha']:.1f}.pkl\", \"wb\"))\n",
            "        pickle.dump(ratio_params,\n",
            "                    open(f\"settings/ratio_params_maha_{data_gen_params['maha']:.1f}.pkl\", \"wb\"))\n",
            "        pickle.dump(testsize_params,\n",
            "                    open(f\"settings/testsize_params_maha_{data_gen_params['maha']:.1f}.pkl\", \"wb\"))\n",
            "    return samplesize_params, nfeats_params, ratio_params, testsize_params\n",
            "\n",
            "\n",
            "for maha in maha_values:\n",
            "    data_dir = os.path.join(os.environ[\"HOME\"], \"data\")\n",
            "    results_dir = os.path.join(data_dir, \"sim_results\", f\"maha_{maha:.1f}\")\n",
            "    ## set up directories for saving results\n",
            "    ## results are separated by the the underlying probability distributions (and their mahalanobis distance)\n",
            "    os.makedirs(results_dir, exist_ok=True) "
         ]
      },
      {
         "cell_type": "markdown",
         "id": "13e9af3f",
         "metadata": {},
         "source": [
            "# Post-hoc simulations"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "id": "091ee2d1",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n"
               ]
            }
         ],
         "source": [
            "for maha in maha_values:\n",
            "    samplesize_params, nfeats_params, ratio_params, testsize_params = set_params(maha, save=True)\n",
            "    @simulate(**samplesize_params[\"sim\"])\n",
            "    def simulate_samplesize_post(param=None, seed=None, simno=None, settings=samplesize_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(\n",
            "            X, y, test_size=0.2, shuffle=True\n",
            "        )\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_estimator = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_estimator = estimator\n",
            "        ## use model with tuned penalty\n",
            "        y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = post_hoc_permutation(\n",
            "            y_true=y_test,\n",
            "            y_score=y_pred,\n",
            "            n_permutations=n_permutations,\n",
            "            score_function=score_model,\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"post_samplesize_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "\n",
            "    @simulate(**testsize_params[\"sim\"])\n",
            "    def simulate_testsize_post(param=None, seed=None, simno=None, settings=testsize_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(\n",
            "            X, y, test_size=param, shuffle=True\n",
            "        )\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_estimator = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_estimator = estimator\n",
            "        ## use model with tuned penalty\n",
            "        y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = post_hoc_permutation(\n",
            "            y_true=y_test,\n",
            "            y_score=y_pred,\n",
            "            n_permutations=n_permutations,\n",
            "            score_function=score_model,\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"post_testsize_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "\n",
            "    @simulate(**nfeats_params[\"sim\"])\n",
            "    def simulate_nfeats_post(param=None, seed=None, simno=None, settings=nfeats_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(\n",
            "            X, y, test_size=0.2, shuffle=True\n",
            "        )\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_estimator = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_estimator = estimator\n",
            "        ## use model with tuned penalty\n",
            "        y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = post_hoc_permutation(\n",
            "            y_true=y_test,\n",
            "            y_score=y_pred,\n",
            "            n_permutations=n_permutations,\n",
            "            score_function=score_model,\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"post_nfeats_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "\n",
            "    @simulate(**ratio_params[\"sim\"])\n",
            "    def simulate_ratio_post(param=None, seed=None, simno=None, settings=ratio_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(\n",
            "            X, y, test_size=0.2, shuffle=True\n",
            "        )\n",
            "        ## Simulate validation set, same as original dataset\n",
            "        X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_estimator = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_estimator = estimator\n",
            "        ## use model with tuned penalty\n",
            "        y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = post_hoc_permutation(\n",
            "            y_true=y_test,\n",
            "            y_score=y_pred,\n",
            "            n_permutations=n_permutations,\n",
            "            score_function=score_model,\n",
            "            n_jobs=-1,\n",
            "        )\n",
            "        # save with pickle\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"post_ratio_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "    \n",
            "    testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
            "    samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
            "    nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
            "    ratio_futures_post, ratio_gather = simulate_ratio_post()\n",
            "    # wait for all futures to complete\n",
            "    wait(testsize_futures_post + samplesize_futures_post + nfeats_futures_post + ratio_futures_post)\n",
            "    # give cluster time to clean up before next iteration\n",
            "    time.sleep(60)\n",
            "    "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "id": "c27286a7",
         "metadata": {
            "tags": []
         },
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "# testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
            "# samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
            "# nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
            "# ratio_futures_post, ratio_gather = simulate_ratio_post()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "id": "7a7b42bc",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(samplesize_futures_post + ratio_futures_post + nfeats_futures_post + testsize_futures_post)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "id": "0c1692d9",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.shutdown()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "9aab71d2",
         "metadata": {},
         "source": [
            "# Pre-training permutations (original)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "35e8088e",
         "metadata": {},
         "source": [
            "#### Simulation functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "id": "70173f21",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://10.152.32.35:8787/status\n"
               ]
            }
         ],
         "source": [
            "for maha in maha_values:\n",
            "    samplesize_params, nfeats_params, ratio_params, testsize_params = set_params(maha, save=False)\n",
            "    \n",
            "    @simulate(**samplesize_params[\"sim\"])\n",
            "    def simulate_samplesize_pre(param=None, seed=None, simno=None, settings=samplesize_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_C = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_C = C\n",
            "        ## set up model with tuned penalty\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = pre_training_permutation(\n",
            "            estimator,\n",
            "            X_train, X_test, y_train, y_test,\n",
            "            n_permutations=n_permutations,\n",
            "            score_func=score_model,\n",
            "            verbose=True, n_jobs=-1\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_samplesize_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "    @simulate(**testsize_params[\"sim\"])\n",
            "    def simulate_testsize_pre(param=None, seed=None, simno=None, settings=testsize_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
            "        ## Simulate validation set, same as original dataset\n",
            "        X_val, y_val = random_data_gen(seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_C = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_C = C\n",
            "        ## set up model with tuned penalty\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = pre_training_permutation(\n",
            "            estimator,\n",
            "            X_train, X_test, y_train, y_test,\n",
            "            n_permutations=n_permutations,\n",
            "            score_func=score_model,\n",
            "            verbose=True, n_jobs=-1\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_testsize_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "    @simulate(**nfeats_params[\"sim\"])\n",
            "    def simulate_nfeats_pre(param=None, seed=None, simno=None, settings=nfeats_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(n_feats=param, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_C = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_C = C\n",
            "        ## set up model with tuned penalty\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = pre_training_permutation(\n",
            "            estimator,\n",
            "            X_train, X_test, y_train, y_test,\n",
            "            n_permutations=n_permutations,\n",
            "            score_func=score_model,\n",
            "            verbose=True, n_jobs=-1\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_nfeats_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "\n",
            "    @simulate(**ratio_params[\"sim\"])\n",
            "    def simulate_ratio_pre(param=None, seed=None, simno=None, settings=ratio_params):\n",
            "        settings = deepcopy(settings)\n",
            "        ## Simulate dataset\n",
            "        X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
            "        ## Split into train-test set\n",
            "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "        ## Simulate validation set\n",
            "        X_val, y_val = random_data_gen(class_ratio=param, seed=None, **settings[\"data_gen\"])\n",
            "        ## iterate over possible penalty params\n",
            "        max_AUC = 0\n",
            "        best_C = None\n",
            "        for C in settings[\"classif\"].pop(\"C\"):\n",
            "            estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "            estimator.fit(X=X_train, y=y_train)\n",
            "            y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "            AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "            if AUC >= max_AUC:\n",
            "                max_AUC = AUC\n",
            "                best_C = C\n",
            "        ## set up model with tuned penalty\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "        ## permutations\n",
            "        n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "        score, permutation_scores = pre_training_permutation(\n",
            "            estimator,\n",
            "            X_train, X_test, y_train, y_test,\n",
            "            n_permutations=n_permutations,\n",
            "            score_func=score_model,\n",
            "            verbose=True, n_jobs=-1\n",
            "        )\n",
            "        if settings[\"file\"][\"save\"]:\n",
            "            pickle.dump(\n",
            "                (score, permutation_scores), \n",
            "                open(os.path.join(settings[\"file\"][\"results_dir\"], f\"pre_ratio_{param:.4f}_simno_{simno:05}.pkl\"), \"wb\"))\n",
            "        return score, permutation_scores\n",
            "    testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
            "    samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
            "    nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
            "    ratio_futures_pre, ratio_gather = simulate_ratio_pre()\n",
            "    # wait for all futures to complete\n",
            "    wait(testsize_futures_pre + samplesize_futures_pre + nfeats_futures_pre + ratio_futures_pre)\n",
            "    # give cluster time to clean up before next iteration\n",
            "    time.sleep(60)\n"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "738a79c1-efce-4a4f-a46b-882d3e200d8f",
         "metadata": {},
         "source": [
            "#### Run functions"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "id": "f2e26d45",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
            "samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
            "nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
            "ratio_futures_pre, ratio_gather = simulate_ratio_pre()"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "bc558269-d70f-4bd0-9822-d9538850297b",
         "metadata": {},
         "source": [
            "#### Gather results"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 69,
         "id": "dd86a068",
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/html": [
                     "<div>\n",
                     "<style scoped>\n",
                     "    .dataframe tbody tr th:only-of-type {\n",
                     "        vertical-align: middle;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe tbody tr th {\n",
                     "        vertical-align: top;\n",
                     "    }\n",
                     "\n",
                     "    .dataframe thead th {\n",
                     "        text-align: right;\n",
                     "    }\n",
                     "</style>\n",
                     "<table border=\"1\" class=\"dataframe\">\n",
                     "  <thead>\n",
                     "    <tr style=\"text-align: right;\">\n",
                     "      <th></th>\n",
                     "      <th>exception</th>\n",
                     "      <th>traceback_obj</th>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>param</th>\n",
                     "      <th></th>\n",
                     "      <th></th>\n",
                     "    </tr>\n",
                     "  </thead>\n",
                     "  <tbody>\n",
                     "    <tr>\n",
                     "      <th>0</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e130890540&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>1</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e1241c5780&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e10558c180&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>3</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104dff500&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>4</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e1a59d9380&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>...</th>\n",
                     "      <td>...</td>\n",
                     "      <td>...</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2495</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104e1f740&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2496</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104e4ed00&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2497</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104e1c700&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2498</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104e12e40&gt;</td>\n",
                     "    </tr>\n",
                     "    <tr>\n",
                     "      <th>2499</th>\n",
                     "      <td>TypeError(\"score_model() got an unexpected key...</td>\n",
                     "      <td>&lt;traceback object at 0x14e104fc6900&gt;</td>\n",
                     "    </tr>\n",
                     "  </tbody>\n",
                     "</table>\n",
                     "<p>2480 rows × 2 columns</p>\n",
                     "</div>"
                  ],
                  "text/plain": [
                     "                                               exception  \\\n",
                     "param                                                      \n",
                     "0      TypeError(\"score_model() got an unexpected key...   \n",
                     "1      TypeError(\"score_model() got an unexpected key...   \n",
                     "2      TypeError(\"score_model() got an unexpected key...   \n",
                     "3      TypeError(\"score_model() got an unexpected key...   \n",
                     "4      TypeError(\"score_model() got an unexpected key...   \n",
                     "...                                                  ...   \n",
                     "2495   TypeError(\"score_model() got an unexpected key...   \n",
                     "2496   TypeError(\"score_model() got an unexpected key...   \n",
                     "2497   TypeError(\"score_model() got an unexpected key...   \n",
                     "2498   TypeError(\"score_model() got an unexpected key...   \n",
                     "2499   TypeError(\"score_model() got an unexpected key...   \n",
                     "\n",
                     "                              traceback_obj  \n",
                     "param                                        \n",
                     "0      <traceback object at 0x14e130890540>  \n",
                     "1      <traceback object at 0x14e1241c5780>  \n",
                     "2      <traceback object at 0x14e10558c180>  \n",
                     "3      <traceback object at 0x14e104dff500>  \n",
                     "4      <traceback object at 0x14e1a59d9380>  \n",
                     "...                                     ...  \n",
                     "2495   <traceback object at 0x14e104e1f740>  \n",
                     "2496   <traceback object at 0x14e104e4ed00>  \n",
                     "2497   <traceback object at 0x14e104e1c700>  \n",
                     "2498   <traceback object at 0x14e104e12e40>  \n",
                     "2499   <traceback object at 0x14e104fc6900>  \n",
                     "\n",
                     "[2480 rows x 2 columns]"
                  ]
               },
               "execution_count": 69,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "get_exceptions(testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "id": "5de0fbdf",
         "metadata": {},
         "outputs": [],
         "source": [
            "client.cancel(ratio_futures_pre+nfeats_futures_pre+samplesize_futures_pre+testsize_futures_pre)"
         ]
      },
      {
         "cell_type": "markdown",
         "id": "c87e3da1-4763-4dd5-bf3a-846bd26be597",
         "metadata": {},
         "source": [
            "# Comparing runtime"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 38,
         "id": "ae17d012-36db-417d-b027-95e1e1da0b34",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n",
                  "Running 500 simulations\n",
                  "Using dask client at http://192.168.86.120:51360/status\n"
               ]
            }
         ],
         "source": [
            "runtime_params = {\n",
            "    \"sim\":{\n",
            "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
            "        **sim_params\n",
            "    },\n",
            "    \"data_gen\": {\n",
            "        \"n_feats\":10,\n",
            "        \"class_ratio\":0.5,\n",
            "        **data_gen_params\n",
            "    },\n",
            "    \"classif\": class_params,\n",
            "    \"perm\": permutation_params\n",
            "}\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_pre(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## set up model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, null, p = pre_training_permutation(\n",
            "        estimator,\n",
            "        X_train, X_test, y_train, y_test,\n",
            "        n_permutations=n_permutations,\n",
            "        score_func=roc_auc_score,\n",
            "        verbose=True, n_jobs=-1\n",
            "    )\n",
            "    stop = time.time()\n",
            "    return stop - start\n",
            "\n",
            "@simulate(**runtime_params[\"sim\"])\n",
            "def simulate_runtime_post(param=None, seed=None, settings=runtime_params):\n",
            "    start = time.time()\n",
            "    settings = deepcopy(settings)\n",
            "    ## Simulate dataset\n",
            "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## Split into train-test set\n",
            "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
            "    ## Simulate validation set, same as original dataset\n",
            "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
            "    ## iterate over possible penalty params\n",
            "    max_AUC = 0\n",
            "    best_C = None\n",
            "    for C in settings[\"classif\"].pop(\"C\"):\n",
            "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
            "        estimator.fit(X=X_train, y=y_train)\n",
            "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
            "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
            "        best_C = C if AUC>max_AUC else best_C\n",
            "    ## train model with tuned penalty\n",
            "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
            "    estimator.fit(X=X_train, y=y_train)\n",
            "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
            "    ## permutations\n",
            "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
            "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
            "        y_true=y_test, y_score=y_pred,\n",
            "        n_permutations=n_permutations, n_jobs=-1,\n",
            "        )\n",
            "    stop = time.time()\n",
            "    return stop - start"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 39,
         "id": "c0ef8706-3676-4d6e-a650-34eb85eb7f44",
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2500 parallel jobs\n",
                  "2500 parallel jobs\n"
               ]
            }
         ],
         "source": [
            "runtime_futures_pre, runtime_gather = simulate_runtime_pre()\n",
            "runtime_futures_post, runtime_gather = simulate_runtime_post()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 47,
         "id": "d57fba68-910f-4e9c-80f2-3182889f597b",
         "metadata": {},
         "outputs": [],
         "source": [
            "runtime_result_pre = runtime_gather(runtime_futures_pre)\n",
            "runtime_result_post = runtime_gather(runtime_futures_post)\n",
            "df_result_pre = pd.DataFrame(runtime_result_pre).melt(var_name=\"param\")\n",
            "df_result_post = pd.DataFrame(runtime_result_post).melt(var_name=\"param\")\n",
            "df_result_pre['test'] = 'pre'\n",
            "df_result_post['test'] = 'post'\n",
            "df_result = pd.concat([df_result_pre, df_result_post])\n",
            "df_result._metadata = runtime_params\n",
            "df_result.to_pickle(f\"sim_results/simulate_runtime.pkl\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "id": "13329d27",
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": "permutation-tests-aQMIHBsu-py3.11",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.12.4"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 5
}
