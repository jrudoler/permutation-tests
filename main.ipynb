{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ac5d68-4055-4066-95c0-a7a5e0a7ca43",
   "metadata": {},
   "source": [
    "# Setup and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "099cd60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore', FutureWarning)\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import (permutation_test_score, learning_curve, LeaveOneGroupOut,\n",
    "                                     KFold, cross_val_score, cross_val_predict, cross_validate,\n",
    "                                     train_test_split)\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.base import clone\n",
    "from sklearn import datasets\n",
    "from joblib.parallel import Parallel, delayed\n",
    "import pickle\n",
    "from permutation_helpers import random_data_gen, post_hoc_permutation\n",
    "from simulate import simulate\n",
    "from dask.distributed import progress, Client, wait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461f0030",
   "metadata": {},
   "source": [
    "## Set up client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3dbe440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cmldask.CMLDask as da\n",
    "# rhino_client = da.new_dask_client_slurm(\n",
    "#     job_name=\"simulations\",\n",
    "#     memory_per_job=\"2GB\",\n",
    "#     max_n_jobs=400, threads_per_job=1, \n",
    "#     adapt=False,\n",
    "#     local_directory=\"/home1/jrudoler/dask-worker-space\",\n",
    "#     log_directory=\"/home1/jrudoler/logs/\",\n",
    "# )\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9af3f",
   "metadata": {},
   "source": [
    "# Post-hoc simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad8803",
   "metadata": {},
   "source": [
    "#### Post-hoc simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f932880",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shared parameters\n",
    "class_params = {\n",
    "        \"C\":np.logspace(np.log10(1e-4), np.log10(1e5), 8),\n",
    "        \"class_weight\":\"balanced\"\n",
    "    }\n",
    "permutation_params = {\n",
    "        \"n_permutations\": 5000\n",
    "    }\n",
    "sim_params = {\"n_sim\": 500}\n",
    "data_gen_params = {\n",
    "    \"maha\":np.linspace(0., 1.5, 5)[4],\n",
    "    \"psi_diag\": 1.0,\n",
    "    \"psi_offdiag\": 0.,\n",
    "    \"ddof\": 150\n",
    "}\n",
    "samplesize_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"maha\":0.,\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "        \n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "nfeats_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"maha\":0.,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "ratio_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        \"maha\":0.,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "testsize_params_post = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50323c21",
   "metadata": {},
   "source": [
    "#### Simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8eccfaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n",
      "Running 500 simulations\n",
      "No dask client available, running sequentially\n"
     ]
    }
   ],
   "source": [
    "@simulate(**samplesize_params_post[\"sim\"])\n",
    "def simulate_samplesize_post(param=None, seed=None, settings=samplesize_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_estimator = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_estimator = estimator\n",
    "    ## use model with tuned penalty\n",
    "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**testsize_params_post[\"sim\"])\n",
    "def simulate_testsize_post(param=None, seed=None, settings=testsize_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_estimator = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_estimator = estimator\n",
    "    ## use model with tuned penalty\n",
    "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**nfeats_params_post[\"sim\"])\n",
    "def simulate_nfeats_post(param=None, seed=None, settings=nfeats_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(n_feats=param, n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_estimator = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_estimator = estimator\n",
    "    ## use model with tuned penalty\n",
    "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue\n",
    "\n",
    "@simulate(**ratio_params_post[\"sim\"])\n",
    "def simulate_ratio_post(param=None, seed=None, settings=ratio_params_post):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(class_ratio=param, n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_estimator = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_estimator = estimator\n",
    "    ## use model with tuned penalty\n",
    "    y_pred = best_estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    return score, permutation_scores, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0941b9ea",
   "metadata": {},
   "source": [
    "#### Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27286a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "testsize_futures_post, testsize_gather = simulate_testsize_post()\n",
    "samplesize_futures_post, samplesize_gather = simulate_samplesize_post()\n",
    "nfeats_futures_post, nfeats_gather = simulate_nfeats_post()\n",
    "ratio_futures_post, ratio_gather = simulate_ratio_post()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9603cac4",
   "metadata": {},
   "source": [
    "#### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2e6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(f\"sim_results/maha_{data_gen_params['maha']:.1f}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc05025",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(testsize_futures_post)\n",
    "testsize_result = testsize_gather(testsize_futures_post) \n",
    "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = testsize_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_post.pkl\")\n",
    "rhino_client.cancel(testsize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acbffffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(samplesize_futures_post)\n",
    "samplesize_result = samplesize_gather(samplesize_futures_post) \n",
    "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = samplesize_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_post.pkl\")\n",
    "rhino_client.cancel(samplesize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5f3154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(nfeats_futures_post)\n",
    "nfeats_result = nfeats_gather(nfeats_futures_post)\n",
    "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = nfeats_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_post.pkl\")\n",
    "rhino_client.cancel(nfeats_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72d7efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(ratio_futures_post)\n",
    "ratio_result = ratio_gather(ratio_futures_post)\n",
    "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = ratio_params_post\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_post.pkl\")\n",
    "rhino_client.cancel(ratio_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7a7b42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(samplesize_futures_post + ratio_futures_post + nfeats_futures_post + testsize_futures_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0c1692d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aab71d2",
   "metadata": {},
   "source": [
    "# Pre-training permutations (original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f2519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _train_score(estimator, X_train, X_test, y_train, y_test, \n",
    "                score_func, shuffle_labels=False):\n",
    "    if shuffle_labels:\n",
    "        indices = np.random.default_rng().permutation(len(y_train))\n",
    "        y_train = y_train[indices]\n",
    "    estimator.fit(X_train, y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:,1]\n",
    "    score = score_func(y_true=y_test, y_score=y_pred)\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def pre_training_permutation(estimator, X_train, X_test, y_train, y_test,\n",
    "                            n_permutations, score_func, verbose=False, n_jobs=None):\n",
    "    score = _train_score(\n",
    "        clone(estimator), X_train, X_test, y_train, y_test, score_func, shuffle_labels=False\n",
    "    )\n",
    "    permutation_scores = Parallel(n_jobs=n_jobs, verbose=verbose)(\n",
    "        delayed(_train_score)(\n",
    "            clone(estimator),\n",
    "            X_train, X_test, y_train, y_test,\n",
    "            score_func,\n",
    "            shuffle_labels=True,\n",
    "        )\n",
    "        for _ in range(n_permutations)\n",
    "    )\n",
    "    permutation_scores = np.array(permutation_scores)\n",
    "    pvalue = (np.sum(permutation_scores >= score) + 1.0) / (n_permutations + 1)\n",
    "    return score, permutation_scores, pvalue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835f9fb8",
   "metadata": {},
   "source": [
    "#### Simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aca895a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### shared parameters\n",
    "# class_params = {\n",
    "#     \"C\":1e-3,\n",
    "#     \"class_weight\":\"balanced\"\n",
    "# }\n",
    "# permutation_params = {\n",
    "#     \"n_permutations\": 5000\n",
    "# }\n",
    "# sim_params = {\"n_sim\": 150}\n",
    "# data_gen_params = {\n",
    "#     \"maha\":np.linspace(0., 1.5, 5)[0],\n",
    "#     \"psi_diag\": 1.0,\n",
    "#     \"psi_offdiag\": 0.,\n",
    "#     \"ddof\": 150\n",
    "# }\n",
    "samplesize_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "        \n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "nfeats_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(1, 10, 5, base=2).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "ratio_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\": np.logspace(np.log10(.01), np.log10(.5), 5), #np.linspace(.1, .9, 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "testsize_params_pre = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(np.log10(.01), np.log10(.5), 5),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_samples\":1000,\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8088e",
   "metadata": {},
   "source": [
    "#### Simulation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70173f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.101:51360/status\n"
     ]
    }
   ],
   "source": [
    "@simulate(**samplesize_params_pre[\"sim\"])\n",
    "def simulate_samplesize_pre(param=None, seed=None, settings=samplesize_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_C = C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**testsize_params_pre[\"sim\"])\n",
    "def simulate_testsize_pre(param=None, seed=None, settings=testsize_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=param, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_C = C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**nfeats_params_pre[\"sim\"])\n",
    "def simulate_nfeats_pre(param=None, seed=None, settings=nfeats_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_feats=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(n_feats=param, n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_C = C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p\n",
    "\n",
    "@simulate(**ratio_params_pre[\"sim\"])\n",
    "def simulate_ratio_pre(param=None, seed=None, settings=ratio_params_pre):\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(class_ratio=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set\n",
    "    X_val, y_val = random_data_gen(class_ratio=param, n_samples=1000, seed=None, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        if AUC >= max_AUC:\n",
    "            max_AUC = AUC\n",
    "            best_C = C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    return score, null, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738a79c1-efce-4a4f-a46b-882d3e200d8f",
   "metadata": {},
   "source": [
    "#### Run functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2e26d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "testsize_futures_pre, testsize_gather = simulate_testsize_pre()\n",
    "samplesize_futures_pre, samplesize_gather = simulate_samplesize_pre()\n",
    "nfeats_futures_pre, nfeats_gather = simulate_nfeats_pre()\n",
    "ratio_futures_pre, ratio_gather = simulate_ratio_pre()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc558269-d70f-4bd0-9822-d9538850297b",
   "metadata": {},
   "source": [
    "#### Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65445e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(testsize_futures_pre)\n",
    "testsize_result = testsize_gather(testsize_futures_pre) \n",
    "df_result = pd.DataFrame(testsize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = testsize_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_testsize_pre.pkl\")\n",
    "rhino_client.cancel(testsize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754db625",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(samplesize_futures_pre)\n",
    "samplesize_result = samplesize_gather(samplesize_futures_pre) \n",
    "df_result = pd.DataFrame(samplesize_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = samplesize_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_samplesize_pre.pkl\")\n",
    "rhino_client.cancel(samplesize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe27f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(nfeats_futures_pre)\n",
    "nfeats_result = nfeats_gather(nfeats_futures_pre)\n",
    "df_result = pd.DataFrame(nfeats_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = nfeats_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_nfeats_pre.pkl\")\n",
    "rhino_client.cancel(nfeats_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait(ratio_futures_pre)\n",
    "ratio_result = ratio_gather(ratio_futures_pre)\n",
    "df_result = pd.DataFrame(ratio_result).melt(var_name=\"param\")\n",
    "df_result[[\"score\", \"perm_scores\", \"pval\"]] = df_result['value'].apply(pd.Series)\n",
    "df_result = df_result.drop(columns='value')\n",
    "df_result._metadata = ratio_params_pre\n",
    "df_result.to_pickle(f\"sim_results/maha_{data_gen_params['maha']:.1f}/simulate_ratio_pre.pkl\")\n",
    "rhino_client.cancel(ratio_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f459839-0113-4b79-8dff-8a9808882216",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(ratio_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5de0fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rhino_client.cancel(ratio_futures_pre+nfeats_futures_pre+samplesize_futures_pre+testsize_futures_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e87e2457-c95f-4af5-8c11-9b52b1ff06ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exception</th>\n",
       "      <th>traceback_obj</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>param</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b42fe391ec0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4320207f40&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b432015bc00&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43099f7640&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43250bb100&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4320f934c0&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b434257e440&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4342099880&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b4313809600&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>NameError(\"name 'pre_training_permutation' is ...</td>\n",
       "      <td>&lt;traceback object at 0x2b43131e3800&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               exception  \\\n",
       "param                                                      \n",
       "0      NameError(\"name 'pre_training_permutation' is ...   \n",
       "1      NameError(\"name 'pre_training_permutation' is ...   \n",
       "2      NameError(\"name 'pre_training_permutation' is ...   \n",
       "3      NameError(\"name 'pre_training_permutation' is ...   \n",
       "4      NameError(\"name 'pre_training_permutation' is ...   \n",
       "...                                                  ...   \n",
       "2495   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2496   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2497   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2498   NameError(\"name 'pre_training_permutation' is ...   \n",
       "2499   NameError(\"name 'pre_training_permutation' is ...   \n",
       "\n",
       "                              traceback_obj  \n",
       "param                                        \n",
       "0      <traceback object at 0x2b42fe391ec0>  \n",
       "1      <traceback object at 0x2b4320207f40>  \n",
       "2      <traceback object at 0x2b432015bc00>  \n",
       "3      <traceback object at 0x2b43099f7640>  \n",
       "4      <traceback object at 0x2b43250bb100>  \n",
       "...                                     ...  \n",
       "2495   <traceback object at 0x2b4320f934c0>  \n",
       "2496   <traceback object at 0x2b434257e440>  \n",
       "2497   <traceback object at 0x2b4342099880>  \n",
       "2498   <traceback object at 0x2b4313809600>  \n",
       "2499   <traceback object at 0x2b43131e3800>  \n",
       "\n",
       "[2500 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "da.get_exceptions(samplesize_futures_pre, range(len(samplesize_futures_pre)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87e3da1-4763-4dd5-bf3a-846bd26be597",
   "metadata": {},
   "source": [
    "# Comparing runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae17d012-36db-417d-b027-95e1e1da0b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.120:51360/status\n",
      "Running 500 simulations\n",
      "Using dask client at http://192.168.86.120:51360/status\n"
     ]
    }
   ],
   "source": [
    "runtime_params = {\n",
    "    \"sim\":{\n",
    "        \"parameter_range\":np.logspace(2, 5, 5).astype(int),\n",
    "        **sim_params\n",
    "    },\n",
    "    \"data_gen\": {\n",
    "        \"n_feats\":10,\n",
    "        \"class_ratio\":0.5,\n",
    "        **data_gen_params\n",
    "    },\n",
    "    \"classif\": class_params,\n",
    "    \"perm\": permutation_params\n",
    "}\n",
    "\n",
    "@simulate(**runtime_params[\"sim\"])\n",
    "def simulate_runtime_pre(param=None, seed=None, settings=runtime_params):\n",
    "    start = time.time()\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## set up model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, null, p = pre_training_permutation(\n",
    "        estimator,\n",
    "        X_train, X_test, y_train, y_test,\n",
    "        n_permutations=n_permutations,\n",
    "        score_func=roc_auc_score,\n",
    "        verbose=True, n_jobs=-1\n",
    "    )\n",
    "    stop = time.time()\n",
    "    return stop - start\n",
    "\n",
    "@simulate(**runtime_params[\"sim\"])\n",
    "def simulate_runtime_post(param=None, seed=None, settings=runtime_params):\n",
    "    start = time.time()\n",
    "    settings = deepcopy(settings)\n",
    "    ## Simulate dataset\n",
    "    X, y = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## Split into train-test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, shuffle=True)\n",
    "    ## Simulate validation set, same as original dataset\n",
    "    X_val, y_val = random_data_gen(n_samples=param, seed=seed, **settings[\"data_gen\"])\n",
    "    ## iterate over possible penalty params\n",
    "    max_AUC = 0\n",
    "    best_C = None\n",
    "    for C in settings[\"classif\"].pop(\"C\"):\n",
    "        estimator = LogisticRegression(**settings[\"classif\"], C=C)\n",
    "        estimator.fit(X=X_train, y=y_train)\n",
    "        y_pred = estimator.predict_proba(X_val)[:, 1]\n",
    "        AUC = roc_auc_score(y_score=y_pred, y_true=y_val)\n",
    "        best_C = C if AUC>max_AUC else best_C\n",
    "    ## train model with tuned penalty\n",
    "    estimator = LogisticRegression(**settings[\"classif\"], C=best_C)\n",
    "    estimator.fit(X=X_train, y=y_train)\n",
    "    y_pred = estimator.predict_proba(X_test)[:, 1]\n",
    "    ## permutations\n",
    "    n_permutations = settings[\"perm\"][\"n_permutations\"]\n",
    "    score, permutation_scores, pvalue = post_hoc_permutation(\n",
    "        y_true=y_test, y_score=y_pred,\n",
    "        n_permutations=n_permutations, n_jobs=-1,\n",
    "        )\n",
    "    stop = time.time()\n",
    "    return stop - start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0ef8706-3676-4d6e-a650-34eb85eb7f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500 parallel jobs\n",
      "2500 parallel jobs\n"
     ]
    }
   ],
   "source": [
    "runtime_futures_pre, runtime_gather = simulate_runtime_pre()\n",
    "runtime_futures_post, runtime_gather = simulate_runtime_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d57fba68-910f-4e9c-80f2-3182889f597b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_result_pre = runtime_gather(runtime_futures_pre)\n",
    "runtime_result_post = runtime_gather(runtime_futures_post)\n",
    "df_result_pre = pd.DataFrame(runtime_result_pre).melt(var_name=\"param\")\n",
    "df_result_post = pd.DataFrame(runtime_result_post).melt(var_name=\"param\")\n",
    "df_result_pre['test'] = 'pre'\n",
    "df_result_post['test'] = 'post'\n",
    "df_result = pd.concat([df_result_pre, df_result_post])\n",
    "df_result._metadata = runtime_params\n",
    "df_result.to_pickle(f\"sim_results/simulate_runtime.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13329d27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
